Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   03/05/25 21:09:42
ui512md.asm						     Page 1 - 1


				;
				;			ui512md
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			File:			ui512md.asm
				;			Author:			John G. Lynch
				;			Legal:			Copyright @2024, per MIT License below
				;			Date:			June 20, 2024
				;
				;			Notes:
				;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
				;
				;				ui512a provides basic operations: zero, copy, compare, add, subtract.
				;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
				;               ui512md provides multiply and divide.
				;
				;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
				;				(currently using VS Community 2022 17.9.6)
				;
				;				It provides external signatures that allow linkage to C and C++ programs,
				;				where a shell/wrapper could encapsulate the methods as part of an object.
				;
				;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
				;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
				;
				;				If processor extensions are used, the caller must align the variables declared and passed
				;				on the appropriate byte boundary (e.g. alignas 64 for 512)
				;
				;				This module is very light-weight (less than 1K bytes) and relatively fast,
				;				but is not intended for all processor types or all environments. 
				;
				;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			MIT License
				;
				;			Copyright (c) 2024 John G. Lynch
				;
				;				Permission is hereby granted, free of charge, to any person obtaining a copy
				;				of this software and associated documentation files (the "Software"), to deal
				;				in the Software without restriction, including without limitation the rights
				;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
				;				copies of the Software, and to permit persons to whom the Software is
				;				furnished to do so, subject to the following conditions:
				;
				;				The above copyright notice and this permission notice shall be included in all
				;				copies or substantial portions of the Software.
				;
				;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
				;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
				;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
				;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
				;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
				;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
				;				SOFTWARE.
				;
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
								INCLUDE			ui512aMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512aMacros
			      C ;
			      C ;			File:			ui512aMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			May 13, 2024
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;
			      C ;				ui512a provides basic operations: zero, copy, compare, add, subtract.
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
			      C ;               ui512md provides multiply and divide.
			      C ;
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;
			      C ;				This module is very light-weight (less than 2K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;
			      C ;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C .list
			      C IFNDEF			ui512aMacros_INC
 = 1			      C ui512aMacros_INC EQU		<1>
			      C 
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512a.asm)
			      C 
			      C ;	// void zero_u ( u64* destarr ); 
			      C ;	// fill supplied 512bit (8 QWORDS) with zero
			      C EXTERNDEF		zero_u:PROC
			      C 
			      C ;	// void copy_u ( u64* destarr, u64* srcarr );
			      C ;	// copy supplied 512bit (8 QWORDS) source to supplied destination
			      C EXTERNDEF		copy_u:PROC
			      C 
			      C ;	// void set_uT64 ( u64* destarr, u64 value );
			      C ;	// set supplied destination 512 bit to supplied u64 value
			      C EXTERNDEF		set_uT64:PROC
			      C 
			      C ;	// s16 compare_u ( u64* lh_op, u64* rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_u:PROC
			      C 
			      C ;	// s16 compare_uT64 ( u64* lh_op, u64 rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand (value)
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_uT64:PROC
			      C 
			      C ;	// s16 add_u ( u64* sum, u64* addend1, u64* addend2 );
			      C ;	// add supplied 512bit (8 QWORDS) sources, place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_u:PROC
			      C 
			      C ;	// s16 add_uT64 ( u64* sum, u64* addend1, u64 addend2 );
			      C ;	// add 64bit QWORD (value) to supplied 512bit (8 QWORDS), place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_uT64:PROC
			      C 
			      C ;	// s16 sub_u ( u64* difference, u64* left operand, u64* right operand );
			      C ;	// subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_u:PROC
			      C 
			      C ;	// s16 sub_uT64( u64* difference, u64* left operand, u64 right operand );
			      C ;	// subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_uT64:PROC
			      C 
			      C ;			Configuration choices
 = 00000001		      C __UseZ			EQU				1									; Use AVX4 processor features (512 bit registers and instructions)
 = 00000000		      C __UseY			EQU				0									; Use AVX2 processor features (256 bit registers and instructions)
 = 00000000		      C __UseX			EQU				0									; Use SIMD/SSE processor features (128 bit registers and instructions)
 = 00000000		      C __UseQ			EQU				0									; Do not use extensions, use standard x64 bit registers and instructions
			      C ;
 = 00000000		      C __CheckAlign	EQU				0									; User is expected to pass arguments aligned on 64 byte boundaries, 
			      C 																	; This setting enforces that with a check. It should not be necessary, but included to help debugging
			      C 
			      C ;           Some coding shortcuts
 = ZMMWORD PTR		      C ZM_PTR			EQU				ZMMWORD PTR
 = YMMWORD PTR		      C YM_PTR			EQU				YMMWORD PTR
 = XMMWORD PTR		      C XM_PTR			EQU				XMMWORD PTR
 = QWORD PTR		      C Q_PTR			EQU				QWORD PTR
 = DWORD PTR		      C D_PTR			EQU				DWORD PTR
 = WORD PTR		      C W_PTR			EQU				WORD PTR
 = BYTE PTR		      C B_PTR			EQU				BYTE PTR
 = DWORD BCST		      C m32BCST			EQU				DWORD BCST
 = QWORD BCST		      C m64BCST			EQU				QWORD BCST
			      C 
			      C ;			mask codes (for compares using instructions like VPCMPUQ)
 = 00000000		      C CPEQ			EQU				0
 = 00000001		      C CPLT			EQU				1
 = 00000002		      C CPLE			EQU				2
 = 00000003		      C CPFALSE			EQU				3
 = 00000004		      C CPNE			EQU				4
 = 00000005		      C CPGE			EQU				5
 = 00000006		      C CPGT			EQU				6
 = 00000007		      C CPTRUE			EQU				7
			      C 
			      C ;			Mask values (for k reg) used to select particulare QWORDS from X, Y, or Z simd regs
 = 00000001		      C MaskBit0		EQU				B_PTR [ 00000001b ]
 = 00000002		      C MaskBit1		EQU				B_PTR [ 00000010b ]
 = 00000004		      C MaskBit2		EQU				B_PTR [ 00000100b ]
 = 00000008		      C MaskBit3		EQU				B_PTR [ 00001000b ]
 = 00000010		      C MaskBit4		EQU				B_PTR [ 00010000b ]
 = 00000020		      C MaskBit5		EQU				B_PTR [ 00100000b ]
 = 00000040		      C MaskBit6		EQU				B_PTR [ 01000000b ]
 = 00000080		      C MaskBit7		EQU				B_PTR [ 10000000b ]
			      C 
 = 			      C Mask20			EQU
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ; return (if any) is in EAX
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C 
			      C ;===========================================================================================
			      C ;          Local macros
			      C ;===========================================================================================
			      C 
			      C ;
			      C ;			Test passed variable addresses for 64 byte alignment
			      C ;			Note: Better performance if this is off, but for debugging, maybe have it on
			      C ;
			      C 
			      C CheckAlign		MACRO			Raddr
			      C 				LOCAL			ok
			      C 	IF	__CheckAlign
			      C 				TEST			Raddr, 63							; Is specified param aligned 64?
			      C 				JZ				ok									; Yes, passes test, continue
			      C 				INT				0									; No, fails, break (can substitute other exception handling)
			      C ok:
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C MemConstants	MACRO
			      C ;		Return codes commonly used.			
			      C ret0			DD				0								
			      C ret1			DD				1
			      C ret_1			DD				-1
			      C ;		Masks commonly used
			      C mskAll8			DB				255
			      C mskB0			DB				1
			      C mskB1			DB				2
			      C mskB2			DB				4
			      C mskB3			DB				8
			      C mskB4			DB				16
			      C mskB5			DB				32
			      C mskB6			DB				64
			      C mskB7			DB				128
			      C mskHex100		DD				0100h
			      C 				ENDM
			      C 
			      C ;
			      C ;			Zero a 512 bit destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Zero512			MACRO			dest
			      C 				CheckAlign		dest
			      C 	IF	__UseZ
			      C 				VPXORQ			ZMM31, ZMM31, ZMM31
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VPXORQ			YMM4, YMM4, YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM4
			      C 	ELSEIF	__UseX
			      C 				PXOR			XMM4, XMM4
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM4			
			      C 	ELSE
			      C 				XOR				RAX, RAX
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C 
			      C ;
			      C ;			Copy a 512 bit source to destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Copy512			MACRO			dest, src
			      C 				CheckAlign		dest
			      C 				CheckAlign		src
			      C 	IF	__UseZ
			      C 				VMOVDQA64		ZMM31, ZM_PTR [ src ]
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VMOVDQA64		YMM4, YM_PTR [ src + 0 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			      C 				VMOVDQA64		YMM5, YM_PTR [ src + 4 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM5
			      C 	ELSEIF	__UseX
			      C 				MOVDQA			XMM4, XM_PTR [ src + 0 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 2 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM3
			      C 				MOVDQA			XMM4, XM_PTR [ src + 4 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 6 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM3
			      C 	ELSE
			      C 				MOV				RAX, [ src + 0 * 8 ]
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				RAX, [ src + 1 * 8 ]
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				RAX, [ src + 2 * 8 ]
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				RAX, [ src + 3 * 8 ]
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				RAX, [ src + 4 * 8 ]
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				RAX, [ src + 5 * 8 ]
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				RAX, [ src + 6 * 8 ]
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				RAX, [ src + 7 * 8 ]
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C ;
			      C ;			Get a GP reg QWORD from within a Z register as specified by mask
			      C ;			Note: RAX, ZMM0 and k1 are used and not restored
			      C ;			Example usage: GetZatIdx R11, ZMM1, MaskBit2 or SetZatIdx ZMM1, R12, [ R9 ]  (where R9 is a bit mask, not an integer index)
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C GetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX,  mask
			      C 				KMOVB			k1, RAX
			      C 				VPCOMPRESSQ		ZMM0 {k1}{z}, src
			      C 				VMOVQ			dest, XMM0
			      C 				ENDM
			      C 
			      C ;
			      C ;			Set a GP Reg QWORD within a Z register as specified by mask
			      C ;			Note: RAX and k1 are used and not restored
			      C ;			Example usage: SetZatIdx ZMM1, R8, MaskBit2
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C SetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX, mask
			      C 				KMOVB			k1, RAX
			      C 				VPBROADCASTQ 	dest {k1}, src
			      C 				ENDM
			      C ENDIF
			      C 
								INCLUDE			ui512bMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512bMacros
			      C ;
			      C ;			File:			ui512bMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			June 11, 2024
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;				The basic operations: zero, copy, compare, add, subtract.
			      C ;               Other optional modules provide bit ops and multiply / divide.
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;				This module is very light-weight (less than 1K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;				Use for private (hobbyist), or instructional,
			      C ;				or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not,
			      C ;               least significant bit and most significant bit.
			      C ;
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C 
			      C IFNDEF						ui512bMacros_INC
 = 1			      C ui512bMacros_INC EQU		<1>
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512b.asm)
			      C 
			      C ;   // void shr_u ( u64* destination, u64* source, u32 bits_to_shift )
			      C ;   // shift supplied source 512bit (8 QWORDS) right, put in destination
			      C EXTERNDEF	shr_u:PROC
			      C 
			      C ;   // void shl_u ( u64* destination, u64* source, u16 bits_to_shift );
			      C ;   // shift supplied source 512bit (8 QWORDS) left, put in destination
			      C EXTERNDEF	shl_u:PROC
			      C 
			      C ;   // void and_u ( u64* destination, u64* lh_op, u64* rh_op );
			      C ;   // logical 'AND' bits in lh_op, rh_op, put result in destination
			      C EXTERNDEF	and_u:PROC
			      C 
			      C ;   // logical 'OR' bits in lh_op, rh_op, put result in destination
			      C ;   // void or_u( u64* destination, u64* lh_op, u64* rh_op);
			      C EXTERNDEF	or_u:PROC
			      C 
			      C ;   // logical 'NOT' bits in source, put result in destination
			      C ;	// void not_u( u64* destination, u64* source);
			      C EXTERNDEF	not_u:PROC
			      C 
			      C ;   // find most significant bit in supplied source 512bit (8 QWORDS)
			      C ;	// s16 msb_u( u64* );
			      C ;   // returns: -1 if no most significant bit, bit number otherwise, bits numbered 0 to 511 inclusive
			      C EXTERNDEF	msb_u:PROC
			      C 
			      C ;   // find least significant bit in supplied source 512bit (8 QWORDS)
			      C ;	// s16 lsb_u( u64* );
			      C ;   // returns: -1 if no least significant bit, bit number otherwise, bits numbered 0 to 511 inclusive
			      C EXTERNDEF	lsb_u:PROC
			      C 
			      C ENDIF
			      C 
								INCLUDE			ui512mdMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512mdMacros
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;			File:			ui512mdMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			June 20, 2024
			      C 
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;
			      C ;				ui512a provides basic operations: zero, copy, compare, add, subtract.
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
			      C ;               ui512md provides multiply and divide.
			      C ;
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;
			      C ;				This module is very light-weight (less than 1K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;
			      C ;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C IFNDEF						ui512mdMacros_INC
 = 1			      C ui512mdMacros_INC EQU		<1>
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;			signatures (from ui512md.asm)
			      C 
			      C ;			mult_uT64		-	multiply 512 bit multiplicand by 64 bit multiplier, giving 512 product, 64 bit overflow
			      C ;			Prototype:		-	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
			      C EXTERNDEF	mult_uT64:PROC	;	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
			      C 
			      C ;			mult_u			-	multiply 512 multiplicand by 512 multiplier, giving 512 product, overflow
			      C ;			Prototype:		-	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
			      C EXTERNDEF	mult_u:PROC		;	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
			      C 
			      C ;			div_uT64		-	divide 512 bit dividend by 64 bit bit divisor, giving 512 bit quotient and 64 bit remainder
			      C ;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64 divisor,);
			      C EXTERNDEF	div_uT64:PROC	;	s16 div_uT64( u64* quotient, u64* remainder, u64* dividend, u64 divisor);
			      C 
			      C ;			div_u			-	divide 512 bit dividend by 512 bit divisor, giving 512 bit quotient and remainder
			      C ;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
			      C EXTERNDEF	div_u:PROC		;	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C 
			      C CreateFrame	MACRO			argsize, argsavename
			      C ;
			      C ;			set up frame to save regs, and to create aligned working memory for scratch variables
			      C ;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			      C ;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			      C ;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			      C ;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			      C ;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			      C ;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			      C ;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			      C ;			example:
			      C ;
			      C ;somename	PROC
			      C ;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			      C ;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			      C ;			LOCAL		some local variable declarions, some more, and some more
			      C ;			LOCAL		and some more
			      C ;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			      C ;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			      C ;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			      C ;
			      C ;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			      C ;
			      C 			PUSH			RBP
			      C 			MOV				RBP, RSP
			      C 			ADD				RSP, -(( argsize / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
			      C 			MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
			      C 			AND				RSP, RAX
			      C 			AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
			      C 			XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
			      C 			MOV				argsavename, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
			      C 			ENDM
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C 
			      C ReleaseFrame MACRO			argsavename
			      C ;			release memory set up by createframe macro
			      C ;			restores RSP, and RBP to as-called values
			      C ;			after these instructions are executed, no LOCAL variables can be accessed
			      C ;			This needs to be done to restore the stack correctly, but can be done only once
			      C ;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
			      C 			MOV				RBP, argsavename
			      C 			LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
			      C 			ENDM
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C ENDIF
			      C 

								OPTION			casemap:none
 00000000			.CODE			ui512md
								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none

								MemConstants
			     1	;		Return codes commonly used.			
 00000000 00000000	     1	ret0			DD				0								
 00000004 00000001	     1	ret1			DD				1
 00000008 FFFFFFFF	     1	ret_1			DD				-1
			     1	;		Masks commonly used
 0000000C FF		     1	mskAll8			DB				255
 0000000D 01		     1	mskB0			DB				1
 0000000E 02		     1	mskB1			DB				2
 0000000F 04		     1	mskB2			DB				4
 00000010 08		     1	mskB3			DB				8
 00000011 10		     1	mskB4			DB				16
 00000012 20		     1	mskB5			DB				32
 00000013 40		     1	mskB6			DB				64
 00000014 80		     1	mskB7			DB				128
 00000015 00000100	     1	mskHex100		DD				0100h

				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		mult_u:PROC					; void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier)
				;			mult_u			-	multiply 512 multiplicand by 512 multiplier, giving 512 product, overflow
				;			Prototype:		-	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
				;			product			-	Address of 8 QWORDS to store resulting product (in RCX)
				;			overflow		-	Address of 8 QWORDS to store resulting overflow (in RDX)
				;			multiplicand	-	Address of 8 QWORDS multiplicand (in R8)
				;			multiplier		-	Address of 8 QWORDS multiplier (in R9)
				;			returns			-	nothing (0)

 00000019			mult_u			PROC			PUBLIC
								LOCAL			padding1 [ 8 ] : QWORD
								LOCAL			product [ 16 ] : QWORD
								LOCAL			savedRBP : QWORD
								LOCAL			savedRCX : QWORD, savedRDX : QWORD, savedR10 : QWORD, savedR11 : QWORD, savedR12 : QWORD
								LOCAL			plierl : WORD						; low limit index of of multiplier (7 - first non-zero)
								LOCAL			candl : WORD						; low limit index of multiplicand
								LOCAL			padding2 [ 16 ] : QWORD
 = padding2 + 64 - padding1	mult_u_ofs		EQU				padding2 + 64 - padding1			; offset is the size of the local memmory declarations

								CreateFrame		220h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 00000019  55		     1				PUSH			RBP
 0000001A  48/ 8B EC	     1				MOV				RBP, RSP
 0000001D  48/ 81 C4	     1				ADD				RSP, -(( 220h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFD9C
 00000024  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 0000002B  48/ 23 E0	     1				AND				RSP, RAX
 0000002E  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 00000031  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 00000033  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFF38
 0000003A  48/ 89 8D						MOV				savedRCX, RCX
	   FFFFFF30
 00000041  48/ 89 95						MOV				savedRDX, RDX
	   FFFFFF28
 00000048  4C/ 89 95						MOV				savedR10, R10
	   FFFFFF20
 0000004F  4C/ 89 9D						MOV				savedR11, R11
	   FFFFFF18
 00000056  4C/ 89 A5						MOV				savedR12, R12
	   FFFFFF10

								CheckAlign		RCX									; (out) Product
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			RCX, 63							; Is specified param aligned 64?
			     1					JZ				??0000									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0000:
			     1		ENDIF
								CheckAlign		RDX									; (out) Overflow
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			RDX, 63							; Is specified param aligned 64?
			     1					JZ				??0001									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0001:
			     1		ENDIF
								CheckAlign		R8									; (in) Multiplicand
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			R8, 63							; Is specified param aligned 64?
			     1					JZ				??0002									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0002:
			     1		ENDIF
								CheckAlign		R9									; (in) Multiplier
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			R9, 63							; Is specified param aligned 64?
			     1					JZ				??0003									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0003:
			     1		ENDIF

				; Examine multiplicand, save dimensions, handle edge cases of zero or one
 0000005D  49/ 8B C8						MOV				RCX, R8								; examine multiplicand
 00000060  E8 00000000 E					CALL			msb_u
 00000065  66| 83 F8 FF						CMP				AX, -1								; multiplicand = 0? exit with product = 0
 00000069  0F 84 0000012C					JE				@@zeroandexit
 0000006F  66| 83 F8 00						CMP				AX, 0								; multiplicand = 1?	exit with product = multiplier
 00000073  49/ 8B D1						MOV				RDX, R9								; address of multiplier (to be copied to product)
 00000076  0F 84 00000147					JE				@@copyandexit
 0000007C  66| C1 E8 06						SHR				AX, 6								; divide by 64 to get Nr words
 00000080  48/ C7 C1						MOV				RCX, 7
	   00000007
 00000087  66| 2B C8						SUB				CX, AX								; subtract from 7 to get starting (high order) begining index
 0000008A  66| 89 8D						MOV				candl, CX							; save off multiplicand index lower limit (eliminate multiplying leading zero words)
	   FFFFFF0C

				; Examine multiplier, save dimensions, handle edge cases of zero or one
 00000091  49/ 8B C9						MOV				RCX, R9								; examine multiplier
 00000094  E8 00000000 E					CALL			msb_u
 00000099  66| 83 F8 FF						CMP				AX, -1								; multiplier = 0? exit with product = 0
 0000009D  0F 84 000000F8					JE				@@zeroandexit
 000000A3  66| 83 F8 00						CMP				AX, 0								; multiplier = 1? exit with product = multiplicand
 000000A7  49/ 8B D0						MOV				RDX, R8								; address of multiplicand (to be copied to product)
 000000AA  0F 84 00000113					JE				@@copyandexit
 000000B0  66| C1 E8 06						SHR				AX, 6
 000000B4  48/ C7 C1						MOV				RCX, 7
	   00000007
 000000BB  66| 2B C8						SUB				CX, AX
 000000BE  66| 89 8D						MOV				plierl, CX							; save off multiplier index lower limit (eliminate multiplying leading zero words)
	   FFFFFF0E

				; In heap / frame / stack reserved memory, clear 16 word area for overflow/product; set up indexes for loop
 000000C5  48/ 8D 8D						LEA				RCX, product [ 0 ]
	   FFFFFF40
								Zero512			RCX									; clear working copy of overflow, need to start as zero, results are added in
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0004									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0004:
			     2		ENDIF
			     1		IF	__UseZ
 000000CC  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000000D2  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000000D8  48/ 8D 4D 80						LEA				RCX, product[ 8 * 8 ]
								Zero512			RCX									; clear working copy of product (they need to be contiguous, so using working copy, not callers)
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0005									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0005:
			     2		ENDIF
			     1		IF	__UseZ
 000000DC  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000000E2  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000000E8  49/ C7 C3						MOV				R11, 7								; index for multiplier (reduced until less then saved plierl)
	   00000007
 000000EF  49/ C7 C4						MOV				R12, 7								; index for multiplicand (reduced until less than saved candl)
	   00000007

				; multiply loop: an outer loop for each non-zero word of multiplicand, with an inner loop for each non-zero word of multiplier
 000000F6			@@multloop:
 000000F6  4D/ 8B D3						MOV				R10, R11							; R10 holds index for overflow / product work area (results)
 000000F9  4D/ 03 D4						ADD				R10, R12
 000000FC  49/ FF C2						INC				R10									; index for product/overflow 
 000000FF  4B/ 8B 04 E0						MOV				RAX, [ R8 ] + [ R12 * 8 ]			; get qword of multiplicand
 00000103  4B/ F7 24 D9						MUL				Q_PTR [ R9 ] + [ R11 * 8 ]			; multiply by qword of multiplier
 00000107  4A/ 01 84 D5						ADD				product [ R10 * 8 ], RAX
	   FFFFFF40
 0000010F  49/ FF CA						DEC				R10									; preserves carry flag
 00000112			@@:
 00000112  4A/ 11 94 D5						ADC				product [ R10 * 8 ], RDX
	   FFFFFF40
 0000011A  48/ C7 C2						MOV				RDX, 0								; again, preserves carry flag
	   00000000
 00000121  73 05						JNC				@F
 00000123  49/ FF CA						DEC				R10
 00000126  7D EA						JGE				@B
 00000128			@@:																	; next word of multiplicand
 00000128  49/ FF CC						DEC				R12
 0000012B  66| 44/ 3B A5					CMP				R12W, candl
	   FFFFFF0C
 00000133  7D C1						JGE				@@multloop
 00000135  49/ C7 C4						MOV				R12, 7
	   00000007
 0000013C  49/ FF CB						DEC				R11
 0000013F  66| 44/ 3B 9D					CMP				R11W, plierl
	   FFFFFF0E
 00000147  7D AD						JGE				@@multloop							; next word of multiplier

				; copy working product/overflow to callers product / overflow
 00000149  48/ 8B 8D						MOV				RCX, savedRCX
	   FFFFFF30
 00000150  48/ 8D 55 80						LEA				RDX, product [ 8 * 8 ]
								Copy512			RCX, RDX							; copy working product to callers product
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0006									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0006:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0007									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0007:
			     2		ENDIF
			     1		IF	__UseZ
 00000154  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 0000015A  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 00000160  48/ 8B 8D						MOV				RCX, savedRDX
	   FFFFFF28
 00000167  48/ 8D 95						LEA				RDX, product [ 0 ]
	   FFFFFF40
								Copy512			RCX, RDX							; copy working overflow to callers overflow
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0008									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0008:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0009									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0009:
			     2		ENDIF
			     1		IF	__UseZ
 0000016E  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 00000174  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF

				; restore regs, release frame, return
 0000017A			@@exit:			
 0000017A  4C/ 8B 95						MOV				R10, savedR10
	   FFFFFF20
 00000181  4C/ 8B 9D						MOV				R11, savedR11
	   FFFFFF18
 00000188  4C/ 8B A5						MOV				R12, savedR12						; restore any non-volitile regs used
	   FFFFFF10
								ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 0000018F  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFF38
 00000196  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 00000197  48/ 33 C0						XOR				RAX, RAX							; return zero
								RET
 0000019A  C3		   *	    ret    00000h

				; zero callers product and overflow
 0000019B			@@zeroandexit:
 0000019B  48/ 8B 8D						MOV				RCX, savedRCX						; reload address of callers product
	   FFFFFF30
								Zero512			RCX									; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000A									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000A:
			     2		ENDIF
			     1		IF	__UseZ
 000001A2  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001A8  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001AE  48/ 8B 8D						MOV				RCX, savedRDX						; reload address of caller overflow
	   FFFFFF28
								Zero512			RCX									; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000B									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000B:
			     2		ENDIF
			     1		IF	__UseZ
 000001B5  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001BB  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001C1  EB B7						JMP				@@exit

				; multiplying by 1: zero overflow, copy the non-one to the product
 000001C3			@@copyandexit:
 000001C3  48/ 8B 8D						MOV				RCX, savedRDX						; address of passed overflow
	   FFFFFF28
								Zero512			RCX 								; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000C									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000C:
			     2		ENDIF
			     1		IF	__UseZ
 000001CA  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001D0  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001D6  48/ 8B 8D						MOV				RCX, savedRCX						; copy (whichever: multiplier or multiplicand) to callers product
	   FFFFFF30
								Copy512			RCX, RDX							; RDX "passed" here from whomever jumped here (either multiplier, or multiplicand in RDX)
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000D									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000D:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??000E									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000E:
			     2		ENDIF
			     1		IF	__UseZ
 000001DD  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 000001E3  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001E9  EB 8F						JMP				@@exit								; and exit
 000001EB			mult_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		mult_uT64:PROC				;	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
				;			mult_uT64		-	multiply 512 bit multiplicand by 64 bit multiplier, giving 512 product, 64 bit overflow
				;			Prototype:		-	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
				;			product			-	Address of 8 QWORDS to store resulting product (in RCX)
				;			overflow		-	Address of QWORD for resulting overflow (in RDX)
				;			multiplicand	-	Address of 8 QWORDS multiplicand (in R8)
				;			multiplier		-	multiplier QWORD (in R9)
				;			returns			-	nothing (0)

								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none
 000001EB			mult_uT64		PROC			PUBLIC

								LOCAL			padding1 [ 8 ] :QWORD
								LOCAL			product [ 8 ] :QWORD
								LOCAL			savedRBP :QWORD, savedRCX :QWORD, savedRDX :QWORD 
								LOCAL			overflow :QWORD
								LOCAL			padding2 [ 8 ] :QWORD
 = padding2 + 64 - padding1	mult64_oset		EQU				padding2 + 64 - padding1

								CreateFrame		120h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 000001EB  55		     1				PUSH			RBP
 000001EC  48/ 8B EC	     1				MOV				RBP, RSP
 000001EF  48/ 81 C4	     1				ADD				RSP, -(( 120h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFEBC
 000001F6  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 000001FD  48/ 23 E0	     1				AND				RSP, RAX
 00000200  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 00000203  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 00000205  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFF78
 0000020C  48/ 89 8D						MOV				savedRCX, RCX
	   FFFFFF70
 00000213  48/ 89 95						MOV				savedRDX, RDX
	   FFFFFF68

 0000021A  48/ 8D 4D 80						LEA				RCX, product
								Zero512			RCX									; clear working copy of product and overflow
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000F									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000F:
			     2		ENDIF
			     1		IF	__UseZ
 0000021E  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000224  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000022A  48/ 33 C0						XOR				RAX, RAX
 0000022D  48/ 89 85						MOV				overflow, RAX
	   FFFFFF60

				; FOR EACH index of 7 thru 1 (ommiting 0): fetch qword of multiplicand, multiply, add 128 bit (RAX,RDX) to running working product
								FOR				idx, <7, 6, 5, 4, 3, 2, 1>
								MOV				RAX, [ R8 + idx * 8 ]				; multiplicand [ idx ] qword -> RAX
								MUL				R9									; times multiplier -> RAX, RDX
								ADD				product [ idx * 8 ], RAX			; add RAX to working product [ idx ] word
								ADC				product [ (idx - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
								ENDM
 00000234  49/ 8B 40 38	     1					MOV				RAX, [ R8 + 7 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000238  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 0000023B  48/ 01 45 B8	     1					ADD				product [ 7 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000023F  48/ 11 55 B0	     1					ADC				product [ (7 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 00000243  49/ 8B 40 30	     1					MOV				RAX, [ R8 + 6 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000247  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 0000024A  48/ 01 45 B0	     1					ADD				product [ 6 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000024E  48/ 11 55 A8	     1					ADC				product [ (6 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 00000252  49/ 8B 40 28	     1					MOV				RAX, [ R8 + 5 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000256  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 00000259  48/ 01 45 A8	     1					ADD				product [ 5 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000025D  48/ 11 55 A0	     1					ADC				product [ (5 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 00000261  49/ 8B 40 20	     1					MOV				RAX, [ R8 + 4 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000265  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 00000268  48/ 01 45 A0	     1					ADD				product [ 4 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000026C  48/ 11 55 98	     1					ADC				product [ (4 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 00000270  49/ 8B 40 18	     1					MOV				RAX, [ R8 + 3 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000274  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 00000277  48/ 01 45 98	     1					ADD				product [ 3 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000027B  48/ 11 55 90	     1					ADC				product [ (3 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 0000027F  49/ 8B 40 10	     1					MOV				RAX, [ R8 + 2 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000283  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 00000286  48/ 01 45 90	     1					ADD				product [ 2 * 8 ], RAX			; add RAX to working product [ idx ] word
 0000028A  48/ 11 55 88	     1					ADC				product [ (2 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product
 0000028E  49/ 8B 40 08	     1					MOV				RAX, [ R8 + 1 * 8 ]				; multiplicand [ idx ] qword -> RAX
 00000292  49/ F7 E1	     1					MUL				R9									; times multiplier -> RAX, RDX
 00000295  48/ 01 45 88	     1					ADD				product [ 1 * 8 ], RAX			; add RAX to working product [ idx ] word
 00000299  48/ 11 55 80	     1					ADC				product [ (1 - 1) * 8 ], RDX		; and add with carry to [ idx - 1 ] qword of working product

				; Most significant (idx=0), the high order result of the multiply in RDX, goes to the overflow of the caller
 0000029D  49/ 8B 00						MOV				RAX, [ R8 + 0 * 8 ]					; 1st
 000002A0  49/ F7 E1						MUL				R9
 000002A3  48/ 01 45 80						ADD				product [ 0 * 8 ], RAX
 000002A7  48/ 11 95						ADC				overflow, RDX						; last qword overflow is also the operation overflow
	   FFFFFF60

				; clean up, restore, send results back, return
 000002AE  48/ 8B 8D						MOV				RCX, savedRCX						; send results back to caller
	   FFFFFF70
 000002B5  48/ 8D 55 80						LEA				RDX, product
								Copy512			RCX, RDX
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0010									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0010:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0011									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0011:
			     2		ENDIF
			     1		IF	__UseZ
 000002B9  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 000002BF  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000002C5  48/ 8B 85						MOV				RAX, overflow
	   FFFFFF60
 000002CC  48/ 8B 95						MOV				RDX, savedRDX
	   FFFFFF68
 000002D3  48/ 89 02						MOV				Q_PTR [ RDX ], RAX

				; release frame, return
								ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 000002D6  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFF78
 000002DD  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 000002DE  48/ 33 C0						XOR				RAX, RAX							; return zero
								RET
 000002E1  C3		   *	    ret    00000h
 000002E2			mult_uT64		ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		div_u:PROC					; s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor)
				;			div_u			-	divide 512 bit dividend by 512 bit divisor, giving 512 bit quotient and remainder
				;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
				;			quotient		-	Address of 8 QWORDS to store resulting quotient (in RCX)
				;			remainder		-	Address of 8 QWORDs for resulting remainder (in RDX)
				;			dividend		-	Address of 8 QWORDS dividend (in R8)
				;			divisor			-	Address of 8 QWORDs divisor (in R9)
				;			returns			-	0 for success, -1 for attempt to divide by zero

								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none
 000002E2			div_u			PROC			PUBLIC

								LOCAL			padding1 [ 8 ] : QWORD
								LOCAL			currnumerator [ 16 ] : QWORD
								LOCAL			qdiv [ 8 ] : QWORD, quotient [ 8 ] : QWORD, normdivisor [ 8 ] : QWORD
								LOCAL			savedRBP : QWORD
								LOCAL			savedRCX : QWORD, savedRDX : QWORD, savedR8 : QWORD, savedR9 : QWORD
								LOCAL			savedR10 : QWORD, savedR11 : QWORD, savedR12 : QWORD
								LOCAL			qHat : QWORD, rHat : QWORD,	qovf : QWORD
								LOCAL			normf : WORD, jIdx : WORD, dimM : WORD, dimN : WORD
							
								LOCAL			padding2 [ 16 ] : QWORD
 = padding2 + 64 - padding1	div_oset		EQU				padding2 + 64 - padding1

								CreateFrame		320h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 000002E2  55		     1				PUSH			RBP
 000002E3  48/ 8B EC	     1				MOV				RBP, RSP
 000002E6  48/ 81 C4	     1				ADD				RSP, -(( 320h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFC7C
 000002ED  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 000002F4  48/ 23 E0	     1				AND				RSP, RAX
 000002F7  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 000002FA  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 000002FC  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFE78
 00000303  48/ 89 8D						MOV				savedRCX, RCX
	   FFFFFE70
 0000030A  48/ 89 95						MOV				savedRDX, RDX
	   FFFFFE68
 00000311  4C/ 89 85						MOV				savedR8, R8
	   FFFFFE60
 00000318  4C/ 89 8D						MOV				savedR9, R9
	   FFFFFE58
 0000031F  4C/ 89 95						MOV				savedR10, R10
	   FFFFFE50
 00000326  4C/ 89 9D						MOV				savedR11, R11
	   FFFFFE48
 0000032D  4C/ 89 A5						MOV				savedR12, R12
	   FFFFFE40
								;
								Zero512			RCX									; zero callers quotient
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0012									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0012:
			     2		ENDIF
			     1		IF	__UseZ
 00000334  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 0000033A  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 00000340  48/ 8B CA						MOV				RCX, RDX
								Zero512			RCX									; zero callers remainder
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0013									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0013:
			     2		ENDIF
			     1		IF	__UseZ
 00000343  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000349  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000034F  48/ 8D 8D						LEA				RCX, quotient
	   FFFFFEC0
								Zero512			RCX									; zero working quotient
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0014									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0014:
			     2		ENDIF
			     1		IF	__UseZ
 00000356  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 0000035C  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
								;
 00000362  49/ 8B C9						MOV				RCX, R9								; divisor
 00000365  E8 00000000 E					CALL			msb_u								; most significant bit
 0000036A  66| 83 F8 FF						CMP				AX, -1								; msb < 0? 
 0000036E  0F 84 0000025D					JE				divbyzero							; divisor is zero, abort
 00000374  66| 83 F8 40						CMP				AX, 64								; divisor only one 64-bit word?
 00000378  7D 3E						JGE				mbynDiv								; no, do divide of m digit by n digit

				;	divide of m 64-bit digits by one 64 bit divisor
 0000037A  48/ 8B 8D						MOV				RCX, savedRCX						; set up parms for call to div by 64bit: RCX - addr of quotient
	   FFFFFE70
 00000381  48/ 8B 95						MOV				RDX, savedRDX						; RDX - addr of remainder
	   FFFFFE68
 00000388  4C/ 8B 85						MOV				R8, savedR8							; R8 - addr of dividend
	   FFFFFE60
 0000038F  48/ 8B 85						MOV				RAX, savedR9
	   FFFFFE58
 00000396  4C/ 8B 48 38						MOV				R9, Q_PTR [RAX + 7 * 8 ]			; R9 - value of 64 bit divisor
 0000039A  E8 0000023A						CALL			div_uT64
 0000039F  48/ 8B 95						MOV				RDX, savedRDX						; move 64 bit remainder to last word of 8 word remainder
	   FFFFFE68
 000003A6  48/ 8B 02						MOV				RAX, Q_PTR [ RDX ]
 000003A9  48/ 89 42 38						MOV				Q_PTR [ RDX + 7 * 8 ], RAX
 000003AD  48/ 33 C0						XOR				RAX, RAX							; clear first word of remainder (where 64 bit divide put it)
 000003B0  48/ 89 02						MOV				Q_PTR [ RDX ], RAX
 000003B3  E9 000001DC						JMP				cleanupret

				;
				; Going to divide an 'm' digit dividend (u), by an 'n' digit divisor (v)
				;	See Knuth, The Art of Computer Programming, Volume 2, Algorithm D, Pages 272-278
 000003B8			mbynDiv:
 000003B8  66| 89 85						MOV				dimN, AX							; still have divisor msb in AX
	   FFFFFE20
 000003BF  66| C1 A5						SHL				dimN, 6								; div msb by 6 to get msq (most significant qword) aka 'n'
	   FFFFFE20 06
 000003C7  66| 89 85						MOV				normf, AX
	   FFFFFE26
 000003CE  66| 83 8D						OR				normf, 63
	   FFFFFE26 3F
 000003D6  66| B8 0007						MOV				AX, 7
 000003DA  66| 2B 85						SUB				AX, dimN
	   FFFFFE20
 000003E1  66| 89 85						MOV				dimN, AX
	   FFFFFE20
 000003E8  66| B8 003F						MOV				AX, 63
 000003EC  66| 2B 85						SUB				AX, normf							; Nr bits to get leading divisor bit to msb saved at normf
	   FFFFFE26
 000003F3  66| 89 85						MOV				normf, AX
	   FFFFFE26
 000003FA  48/ 33 C0						XOR				RAX, RAX
 000003FD			@@:
 000003FD  66| FF 85						INC				dimM
	   FFFFFE22
 00000404  66| 83 BD						CMP				dimM, 8
	   FFFFFE22 08
 0000040C  0F 84 00000182					JE				cleanupret							; dividend is zero, both quotient and remainder already set to zero, so returm
 00000412  49/ 3B 00						CMP				RAX, [ R8 ]
 00000415  4D/ 8D 40 08						LEA				R8, 8 [ R8 ]
 00000419  74 E2						JZ				@B
 0000041B  66| FF 8D						DEC				dimM								; now have dimensions of divisor (v) which is dimN, and dividend (u) which is dimM
	   FFFFFE22
 00000422  66| B8 0007						MOV				AX, 7
 00000426  66| 2B 85						SUB				AX, dimM
	   FFFFFE22
 0000042D  66| 89 85						MOV				dimM, AX
	   FFFFFE22
 00000434  66| 89 85						MOV				jIdx, AX							; Index of quotient digit, also counter to zero and done with divide
	   FFFFFE24

				; Step D1: Normalize	
								
 0000043B  48/ 8B 95						MOV				RDX, savedR9						; callers divisor
	   FFFFFE58
 00000442  48/ 8D 8D						LEA				RCX, normdivisor					; local copy of divisor, normalized
	   FFFFFE80
 00000449  66| 44/ 8B 85					MOV				R8W, normf
	   FFFFFE26
 00000451  E8 00000000 E					CALL			shl_u								; by shifting until MSB is high bit
								;
 00000456  48/ 8B 95						MOV				RDX, savedR8						; callers dividend
	   FFFFFE60
 0000045D  48/ 8D 4D 80						LEA				RCX, currnumerator [ 8 * 8 ]		; starting numerator is the normalized supplied dividend
 00000461  66| 44/ 8B 85					MOV				R8W, normf
	   FFFFFE26
 00000469  E8 00000000 E					CALL			shl_u
 0000046E  66| 83 BD						CMP				dimM, 0
	   FFFFFE22 00
 00000476  7F 2E						JG				@F
 00000478  48/ 8D 95						LEA				RDX, currnumerator					; zero first eight words of working enumerator
	   FFFFFF40
								Zero512			RDX
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0015									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0015:
			     2		ENDIF
			     1		IF	__UseZ
 0000047F  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000485  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RDX ], ZMM31
	   3A
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RDX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RDX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RDX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RDX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RDX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RDX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RDX + 0 * 8 ], RAX
			     1					MOV				[ RDX + 1 * 8 ], RAX
			     1					MOV				[ RDX + 2 * 8 ], RAX
			     1					MOV				[ RDX + 3 * 8 ], RAX
			     1					MOV				[ RDX + 4 * 8 ], RAX
			     1					MOV				[ RDX + 5 * 8 ], RAX
			     1					MOV				[ RDX + 6 * 8 ], RAX
			     1					MOV				[ RDX + 7 * 8 ], RAX
			     1		ENDIF
 0000048B  48/ 8B 95						MOV				RDX, savedR8
	   FFFFFE60
 00000492  48/ 8B 02						MOV				RAX, [ RDX ]						; if numerator has 8 qwords (dimM = 7), then the shift just lost us high order bits, get them			
 00000495  66| 8B 8D						MOV				CX, normf
	   FFFFFE26
 0000049C  48/ D3 E8						SHR				RAX, CL
 0000049F  48/ 89 85						MOV				currnumerator [ 7 * 8 ], RAX		; store them at m + 1 (the word 'before' the other eight qwords)
	   FFFFFF78

 000004A6			@@:
				;			Step D3: Calculate  q^D3:
 000004A6			D3:
 000004A6  48/ 0F B7 8D						MOVZX			RCX, jIdx
	   FFFFFE24
 000004AE  4C/ 8D 85						LEA				R8, currnumerator [ 7 * 8 ]
	   FFFFFF78
 000004B5  49/ 8B 14 C8						MOV				RDX, [R8 + [ RCX * 8 ] ]				; DIV takes 128 bits, RDX the high 64, RAX the low
 000004B9  48/ FF C1						INC				RCX
 000004BC  49/ 8B 04 C8						MOV				RAX, [R8 + [ RCX * 8] ]
 000004C0  48/ 8B 8D						MOV				RCX, normdivisor
	   FFFFFE80
 000004C7  48/ F7 F1						DIV				RCX
 000004CA  48/ 89 85						MOV				qHat, RAX
	   FFFFFE38
 000004D1  48/ 89 95						MOV				rHat, RDX
	   FFFFFE30

				;			Step D4: Multiply and Subtract
 000004D8			D4:
 000004D8  48/ 8D 8D						LEA				RCX, qdiv
	   FFFFFF00
 000004DF  48/ 8D 95						LEA				RDX, qovf
	   FFFFFE28
 000004E6  4C/ 8D 85						LEA				R8, normdivisor
	   FFFFFE80
 000004ED  4C/ 8B 8D						MOV				R9, qHat
	   FFFFFE38
 000004F4  E8 FFFFFCF2						CALL			mult_uT64							; multiply divisor by trial quotient digit (qHat)
 000004F9  48/ 8B 85						MOV				RAX, qovf
	   FFFFFE28
 00000500  48/ 85 C0						TEST			RAX, RAX
 00000503  0F 85 0000008B					JNZ				cleanupret
 00000509  48/ 8D 8D						LEA				RCX, currnumerator
	   FFFFFF40
 00000510  48/ 8D 95						LEA				RDX, currnumerator
	   FFFFFF40
 00000517  4C/ 8D 85						LEA				R8, qdiv
	   FFFFFF00
 0000051E  E8 00000000 E					CALL			sub_u
 00000523  4D/ 8D 64 24						LEA				R12, 8 [ R12 ]
	   08
 00000528  49/ 83 FC 40						CMP				R12, 8 * 8
 0000052C  0F 8C FFFFFF74					JL				D3

				; Step D5: Test remainder
 00000532			D5:
 00000532  48/ 0F B7 8D						MOVZX				RCX, jIdx
	   FFFFFE24
 0000053A  48/ 8B 85						MOV				RAX, qHat
	   FFFFFE38
 00000541  48/ 89 84 CD						MOV				quotient [ RCX * 8 ], RAX
	   FFFFFEC0

				; Step D6: Add Back
 00000549			D6:

				; Step D7: Loop on j
 00000549			D7:
 00000549  66| FF 85						INC				jIdx
	   FFFFFE24
 00000550  66| F7 85						TEST			jIdx, 8
	   FFFFFE24 0008
 00000559  0F 8C FFFFFF47					JL				D3

				; Step D8: Un Normalize:
 0000055F			D8UnNormalize:
 0000055F  48/ 8B 8D						MOV				RCX, savedRDX						; reduced working numerator is now the remainder
	   FFFFFE68
 00000566  48/ 8D 95						LEA				RDX, currnumerator					; copy to callers remainder
	   FFFFFF40
 0000056D  66| 44/ 8B 85					MOV				R8W, normf
	   FFFFFE26
 00000575  E8 00000000 E					CALL			shr_u
								;
 0000057A  48/ 8B 8D						MOV				RCX, savedRCX						; copy working quotient to callers quotient
	   FFFFFE70
 00000581  48/ 8D 95						LEA				RDX, quotient
	   FFFFFEC0
								Copy512			RCX, RDX
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0016									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0016:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0017									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0017:
			     2		ENDIF
			     1		IF	__UseZ
 00000588  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 0000058E  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 00000594			cleanupret:
 00000594  4C/ 8B A5						MOV				R12, savedR12
	   FFFFFE40
 0000059B  4C/ 8B 9D						MOV				R11, savedR11
	   FFFFFE48
 000005A2  4C/ 8B 95						MOV				R10, savedR10
	   FFFFFE50
 000005A9  4C/ 8B 8D						MOV				R9,  savedR9
	   FFFFFE58
 000005B0  4C/ 8B 85						MOV				R8,  savedR8
	   FFFFFE60
 000005B7  48/ 8B 95						MOV				RDX, savedRDX
	   FFFFFE68
 000005BE  48/ 8B 8D						MOV				RCX, savedRCX						; restore parameter registers back to "as-called" values
	   FFFFFE70
								ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 000005C5  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFE78
 000005CC  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 000005CD  48/ 33 C0						XOR				RAX, RAX							; return zero
 000005D0			exit:
								RET
 000005D0  C3		   *	    ret    00000h
 000005D1			divbyzero:
 000005D1  8B 05 00000008 R					MOV				EAX, ret_1
 000005D7  EB F7						JMP				exit

 000005D9			div_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		div_uT64:PROC				; s16 div_uT64( u64* quotient, u64* remainder, u64* dividend, u64 divisor)
				;			div_uT64		-	divide 512 bit dividend by 64 bit divisor, giving 512 bit quotient and 64 bit remainder
				;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64 divisor);
				;			quotient		-	Address of 8 QWORDS to store resulting quotient (in RCX)
				;			remainder		-	Address of QWORD for resulting remainder (in RDX)
				;			dividend		-	Address of 8 QWORDS dividend (in R8)
				;			divisor			-	Value of 64 bit divisor (in R9)
				;			returns			-	0 for success, -1 for attempt to divide by zero

								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none
 000005D9			div_uT64		PROC			PUBLIC

				; Test divisor for divide by zero				
 000005D9  4D/ 85 C9						TEST			R9, R9
 000005DC  74 63						JZ				@@DivByZero

				; DIV instruction (64-bit) uses RAX and RDX. Need to move RDX (addr of remainder) out of the way; start it off with zero
 000005DE  4C/ 8B D2						MOV				R10, RDX
 000005E1  48/ 33 D2						XOR				RDX, RDX

				; FOR EACH index of 0 thru 7: get qword of dividend, divide by divisor, store qword of quotient
								FOR				idx, <0,1,2,3,4,5,6,7>
								MOV				RAX, Q_PTR [ R8 + idx * 8 ]			; dividend [ idx ] -> RAX
								DIV				R9									; divide by divisor in R9
								MOV				Q_PTR [ RCX + idx * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
								ENDM
 000005E4  49/ 8B 00	     1					MOV				RAX, Q_PTR [ R8 + 0 * 8 ]			; dividend [ idx ] -> RAX
 000005E7  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 000005EA  48/ 89 01	     1					MOV				Q_PTR [ RCX + 0 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 000005ED  49/ 8B 40 08	     1					MOV				RAX, Q_PTR [ R8 + 1 * 8 ]			; dividend [ idx ] -> RAX
 000005F1  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 000005F4  48/ 89 41 08	     1					MOV				Q_PTR [ RCX + 1 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 000005F8  49/ 8B 40 10	     1					MOV				RAX, Q_PTR [ R8 + 2 * 8 ]			; dividend [ idx ] -> RAX
 000005FC  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 000005FF  48/ 89 41 10	     1					MOV				Q_PTR [ RCX + 2 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 00000603  49/ 8B 40 18	     1					MOV				RAX, Q_PTR [ R8 + 3 * 8 ]			; dividend [ idx ] -> RAX
 00000607  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 0000060A  48/ 89 41 18	     1					MOV				Q_PTR [ RCX + 3 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 0000060E  49/ 8B 40 20	     1					MOV				RAX, Q_PTR [ R8 + 4 * 8 ]			; dividend [ idx ] -> RAX
 00000612  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 00000615  48/ 89 41 20	     1					MOV				Q_PTR [ RCX + 4 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 00000619  49/ 8B 40 28	     1					MOV				RAX, Q_PTR [ R8 + 5 * 8 ]			; dividend [ idx ] -> RAX
 0000061D  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 00000620  48/ 89 41 28	     1					MOV				Q_PTR [ RCX + 5 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 00000624  49/ 8B 40 30	     1					MOV				RAX, Q_PTR [ R8 + 6 * 8 ]			; dividend [ idx ] -> RAX
 00000628  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 0000062B  48/ 89 41 30	     1					MOV				Q_PTR [ RCX + 6 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide
 0000062F  49/ 8B 40 38	     1					MOV				RAX, Q_PTR [ R8 + 7 * 8 ]			; dividend [ idx ] -> RAX
 00000633  49/ F7 F1	     1					DIV				R9									; divide by divisor in R9
 00000636  48/ 89 41 38	     1					MOV				Q_PTR [ RCX + 7 * 8 ], RAX		; quotient [ idx ] <- RAX ; Note: remainder in RDX for next divide

				; Last (least significant qword) divide leaves a remainder, store it at callers remainder
 0000063A  49/ 89 12						MOV				Q_PTR [ R10 ], RDX					; remainder to callers remainder
 0000063D  48/ 33 C0						XOR				RAX, RAX							; return zero
 00000640			@@exit:			
 00000640  C3							RET

				;
 00000641			@@DivByZero:
								Zero512			RCX									; Divide by Zero. Could throw fault, but returning zero quotient, zero remainder
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0018									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0018:
			     2		ENDIF
			     1		IF	__UseZ
 00000641  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000647  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000064D  48/ 33 C0						XOR				RAX, RAX
 00000650  49/ 89 02						MOV				Q_PTR [ R10 ] , RAX					;
 00000653  8B 05 00000008 R					MOV				EAX, ret_1							; return error (div by zero)
 00000659  EB E5						JMP				@@exit
 0000065B			div_uT64		ENDP

								END
Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   03/05/25 21:09:42
ui512md.asm						     Symbols 2 - 1




Macros:

                N a m e                 Type

CheckAlign . . . . . . . . . . .	Proc
Copy512  . . . . . . . . . . . .	Proc
CreateFrame  . . . . . . . . . .	Proc
GetZatMask . . . . . . . . . . .	Proc
MemConstants . . . . . . . . . .	Proc
ReleaseFrame . . . . . . . . . .	Proc
SetZatMask . . . . . . . . . . .	Proc
Zero512  . . . . . . . . . . . .	Proc


Segments:

                N a m e                  Length   Align   Class

ui512md  . . . . . . . . . . . .	 0000065B 16	  'CODE'	


Procedures, parameters, and locals:

                N a m e                 Type     Value    Attr

div_uT64 . . . . . . . . . . . .	P 	 000005D9 ui512md	Length= 00000082 Public
  @@exit . . . . . . . . . . . .	L 	 00000640 ui512md	
  @@DivByZero  . . . . . . . . .	L 	 00000641 ui512md	
div_u  . . . . . . . . . . . . .	P 	 000002E2 ui512md	Length= 000002F7 Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  currnumerator  . . . . . . . .	QWord	 rbp - 000000C0
  qdiv . . . . . . . . . . . . .	QWord	 rbp - 00000100
  quotient . . . . . . . . . . .	QWord	 rbp - 00000140
  normdivisor  . . . . . . . . .	QWord	 rbp - 00000180
  savedRBP . . . . . . . . . . .	QWord	 rbp - 00000188
  savedRCX . . . . . . . . . . .	QWord	 rbp - 00000190
  savedRDX . . . . . . . . . . .	QWord	 rbp - 00000198
  savedR8  . . . . . . . . . . .	QWord	 rbp - 000001A0
  savedR9  . . . . . . . . . . .	QWord	 rbp - 000001A8
  savedR10 . . . . . . . . . . .	QWord	 rbp - 000001B0
  savedR11 . . . . . . . . . . .	QWord	 rbp - 000001B8
  savedR12 . . . . . . . . . . .	QWord	 rbp - 000001C0
  qHat . . . . . . . . . . . . .	QWord	 rbp - 000001C8
  rHat . . . . . . . . . . . . .	QWord	 rbp - 000001D0
  qovf . . . . . . . . . . . . .	QWord	 rbp - 000001D8
  normf  . . . . . . . . . . . .	Word	 rbp - 000001DA
  jIdx . . . . . . . . . . . . .	Word	 rbp - 000001DC
  dimM . . . . . . . . . . . . .	Word	 rbp - 000001DE
  dimN . . . . . . . . . . . . .	Word	 rbp - 000001E0
  padding2 . . . . . . . . . . .	QWord	 rbp - 00000260
  mbynDiv  . . . . . . . . . . .	L 	 000003B8 ui512md	
  D3 . . . . . . . . . . . . . .	L 	 000004A6 ui512md	
  D4 . . . . . . . . . . . . . .	L 	 000004D8 ui512md	
  D5 . . . . . . . . . . . . . .	L 	 00000532 ui512md	
  D6 . . . . . . . . . . . . . .	L 	 00000549 ui512md	
  D7 . . . . . . . . . . . . . .	L 	 00000549 ui512md	
  D8UnNormalize  . . . . . . . .	L 	 0000055F ui512md	
  cleanupret . . . . . . . . . .	L 	 00000594 ui512md	
  exit . . . . . . . . . . . . .	L 	 000005D0 ui512md	
  divbyzero  . . . . . . . . . .	L 	 000005D1 ui512md	
mult_uT64  . . . . . . . . . . .	P 	 000001EB ui512md	Length= 000000F7 Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  product  . . . . . . . . . . .	QWord	 rbp - 00000080
  savedRBP . . . . . . . . . . .	QWord	 rbp - 00000088
  savedRCX . . . . . . . . . . .	QWord	 rbp - 00000090
  savedRDX . . . . . . . . . . .	QWord	 rbp - 00000098
  overflow . . . . . . . . . . .	QWord	 rbp - 000000A0
  padding2 . . . . . . . . . . .	QWord	 rbp - 000000E0
mult_u . . . . . . . . . . . . .	P 	 00000019 ui512md	Length= 000001D2 Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  product  . . . . . . . . . . .	QWord	 rbp - 000000C0
  savedRBP . . . . . . . . . . .	QWord	 rbp - 000000C8
  savedRCX . . . . . . . . . . .	QWord	 rbp - 000000D0
  savedRDX . . . . . . . . . . .	QWord	 rbp - 000000D8
  savedR10 . . . . . . . . . . .	QWord	 rbp - 000000E0
  savedR11 . . . . . . . . . . .	QWord	 rbp - 000000E8
  savedR12 . . . . . . . . . . .	QWord	 rbp - 000000F0
  plierl . . . . . . . . . . . .	Word	 rbp - 000000F2
  candl  . . . . . . . . . . . .	Word	 rbp - 000000F4
  padding2 . . . . . . . . . . .	QWord	 rbp - 00000174
  @@multloop . . . . . . . . . .	L 	 000000F6 ui512md	
  @@exit . . . . . . . . . . . .	L 	 0000017A ui512md	
  @@zeroandexit  . . . . . . . .	L 	 0000019B ui512md	
  @@copyandexit  . . . . . . . .	L 	 000001C3 ui512md	


Symbols:

                N a m e                 Type     Value    Attr

B_PTR  . . . . . . . . . . . . .	Text   	 BYTE PTR
CPEQ . . . . . . . . . . . . . .	Number	 00000000h   
CPFALSE  . . . . . . . . . . . .	Number	 00000003h   
CPGE . . . . . . . . . . . . . .	Number	 00000005h   
CPGT . . . . . . . . . . . . . .	Number	 00000006h   
CPLE . . . . . . . . . . . . . .	Number	 00000002h   
CPLT . . . . . . . . . . . . . .	Number	 00000001h   
CPNE . . . . . . . . . . . . . .	Number	 00000004h   
CPTRUE . . . . . . . . . . . . .	Number	 00000007h   
D_PTR  . . . . . . . . . . . . .	Text   	 DWORD PTR
Mask20 . . . . . . . . . . . . .	Text   	 
MaskBit0 . . . . . . . . . . . .	Number	 00000001h   
MaskBit1 . . . . . . . . . . . .	Number	 00000002h   
MaskBit2 . . . . . . . . . . . .	Number	 00000004h   
MaskBit3 . . . . . . . . . . . .	Number	 00000008h   
MaskBit4 . . . . . . . . . . . .	Number	 00000010h   
MaskBit5 . . . . . . . . . . . .	Number	 00000020h   
MaskBit6 . . . . . . . . . . . .	Number	 00000040h   
MaskBit7 . . . . . . . . . . . .	Number	 00000080h   
Q_PTR  . . . . . . . . . . . . .	Text   	 QWORD PTR
W_PTR  . . . . . . . . . . . . .	Text   	 WORD PTR
XM_PTR . . . . . . . . . . . . .	Text   	 XMMWORD PTR
YM_PTR . . . . . . . . . . . . .	Text   	 YMMWORD PTR
ZM_PTR . . . . . . . . . . . . .	Text   	 ZMMWORD PTR
__CheckAlign . . . . . . . . . .	Number	 00000000h   
__UseQ . . . . . . . . . . . . .	Number	 00000000h   
__UseX . . . . . . . . . . . . .	Number	 00000000h   
__UseY . . . . . . . . . . . . .	Number	 00000000h   
__UseZ . . . . . . . . . . . . .	Number	 00000001h   
add_uT64 . . . . . . . . . . . .	L 	 00000000 External
add_u  . . . . . . . . . . . . .	L 	 00000000 External
and_u  . . . . . . . . . . . . .	L 	 00000000 External
compare_uT64 . . . . . . . . . .	L 	 00000000 External
compare_u  . . . . . . . . . . .	L 	 00000000 External
copy_u . . . . . . . . . . . . .	L 	 00000000 External
div_oset . . . . . . . . . . . .	Text   	 padding2 + 64 - padding1
lsb_u  . . . . . . . . . . . . .	L 	 00000000 External
m32BCST  . . . . . . . . . . . .	Text   	 DWORD BCST
m64BCST  . . . . . . . . . . . .	Text   	 QWORD BCST
msb_u  . . . . . . . . . . . . .	L 	 00000000 External
mskAll8  . . . . . . . . . . . .	Byte	 0000000C ui512md	
mskB0  . . . . . . . . . . . . .	Byte	 0000000D ui512md	
mskB1  . . . . . . . . . . . . .	Byte	 0000000E ui512md	
mskB2  . . . . . . . . . . . . .	Byte	 0000000F ui512md	
mskB3  . . . . . . . . . . . . .	Byte	 00000010 ui512md	
mskB4  . . . . . . . . . . . . .	Byte	 00000011 ui512md	
mskB5  . . . . . . . . . . . . .	Byte	 00000012 ui512md	
mskB6  . . . . . . . . . . . . .	Byte	 00000013 ui512md	
mskB7  . . . . . . . . . . . . .	Byte	 00000014 ui512md	
mskHex100  . . . . . . . . . . .	DWord	 00000015 ui512md	
mult64_oset  . . . . . . . . . .	Text   	 padding2 + 64 - padding1
mult_u_ofs . . . . . . . . . . .	Text   	 padding2 + 64 - padding1
not_u  . . . . . . . . . . . . .	L 	 00000000 External
or_u . . . . . . . . . . . . . .	L 	 00000000 External
ret0 . . . . . . . . . . . . . .	DWord	 00000000 ui512md	
ret1 . . . . . . . . . . . . . .	DWord	 00000004 ui512md	
ret_1  . . . . . . . . . . . . .	DWord	 00000008 ui512md	
set_uT64 . . . . . . . . . . . .	L 	 00000000 External
shl_u  . . . . . . . . . . . . .	L 	 00000000 External
shr_u  . . . . . . . . . . . . .	L 	 00000000 External
sub_uT64 . . . . . . . . . . . .	L 	 00000000 External
sub_u  . . . . . . . . . . . . .	L 	 00000000 External
ui512aMacros_INC . . . . . . . .	Text   	 1
ui512bMacros_INC . . . . . . . .	Text   	 1
ui512mdMacros_INC  . . . . . . .	Text   	 1
zero_u . . . . . . . . . . . . .	L 	 00000000 External

	   0 Warnings
	   0 Errors
