Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   03/02/25 21:27:13
ui512md.asm						     Page 1 - 1


				;
				;			ui512md
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			File:			ui512md.asm
				;			Author:			John G. Lynch
				;			Legal:			Copyright @2024, per MIT License below
				;			Date:			June 20, 2024
				;
				;			Notes:
				;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
				;
				;				ui512a provides basic operations: zero, copy, compare, add, subtract.
				;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
				;               ui512md provides multiply and divide.
				;
				;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
				;				(currently using VS Community 2022 17.9.6)
				;
				;				It provides external signatures that allow linkage to C and C++ programs,
				;				where a shell/wrapper could encapsulate the methods as part of an object.
				;
				;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
				;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
				;
				;				If processor extensions are used, the caller must align the variables declared and passed
				;				on the appropriate byte boundary (e.g. alignas 64 for 512)
				;
				;				This module is very light-weight (less than 1K bytes) and relatively fast,
				;				but is not intended for all processor types or all environments. 
				;
				;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;
				;			MIT License
				;
				;			Copyright (c) 2024 John G. Lynch
				;
				;				Permission is hereby granted, free of charge, to any person obtaining a copy
				;				of this software and associated documentation files (the "Software"), to deal
				;				in the Software without restriction, including without limitation the rights
				;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
				;				copies of the Software, and to permit persons to whom the Software is
				;				furnished to do so, subject to the following conditions:
				;
				;				The above copyright notice and this permission notice shall be included in all
				;				copies or substantial portions of the Software.
				;
				;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
				;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
				;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
				;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
				;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
				;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
				;				SOFTWARE.
				;
				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
								INCLUDE			ui512aMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512aMacros
			      C ;
			      C ;			File:			ui512aMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			May 13, 2024
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;
			      C ;				ui512a provides basic operations: zero, copy, compare, add, subtract.
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
			      C ;               ui512md provides multiply and divide.
			      C ;
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;
			      C ;				This module is very light-weight (less than 2K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;
			      C ;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C .list
			      C IFNDEF			ui512aMacros_INC
 = 1			      C ui512aMacros_INC EQU		<1>
			      C 
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512a.asm)
			      C 
			      C ;	// void zero_u ( u64* destarr ); 
			      C ;	// fill supplied 512bit (8 QWORDS) with zero
			      C EXTERNDEF		zero_u:PROC
			      C 
			      C ;	// void copy_u ( u64* destarr, u64* srcarr );
			      C ;	// copy supplied 512bit (8 QWORDS) source to supplied destination
			      C EXTERNDEF		copy_u:PROC
			      C 
			      C ;	// void set_uT64 ( u64* destarr, u64 value );
			      C ;	// set supplied destination 512 bit to supplied u64 value
			      C EXTERNDEF		set_uT64:PROC
			      C 
			      C ;	// s16 compare_u ( u64* lh_op, u64* rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied RH operand
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_u:PROC
			      C 
			      C ;	// s16 compare_uT64 ( u64* lh_op, u64 rh_op );
			      C ;	// compare supplied 512bit (8 QWORDS) LH operand to supplied 64bit RH operand (value)
			      C ;	// returns: (0) for equal, -1 for less than, 1 for greater than (logical, unsigned compare)
			      C EXTERNDEF		compare_uT64:PROC
			      C 
			      C ;	// s16 add_u ( u64* sum, u64* addend1, u64* addend2 );
			      C ;	// add supplied 512bit (8 QWORDS) sources, place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_u:PROC
			      C 
			      C ;	// s16 add_uT64 ( u64* sum, u64* addend1, u64 addend2 );
			      C ;	// add 64bit QWORD (value) to supplied 512bit (8 QWORDS), place in supplied destination
			      C ;	// returns: zero for no carry, 1 for carry (overflow)
			      C EXTERNDEF		add_uT64:PROC
			      C 
			      C ;	// s16 sub_u ( u64* difference, u64* left operand, u64* right operand );
			      C ;	// subtract supplied 512bit (8 QWORDS) RH OP from LH OP giving difference in destination
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_u:PROC
			      C 
			      C ;	// s16 sub_uT64( u64* difference, u64* left operand, u64 right operand );
			      C ;	// subtract supplied 64 bit right hand (64 bit value) op from left hand (512 bit) giving difference
			      C ;	// returns: zero for no borrow, 1 for borrow (underflow)
			      C EXTERNDEF		sub_uT64:PROC
			      C 
			      C ;			Configuration choices
 = 00000001		      C __UseZ			EQU				1									; Use AVX4 processor features (512 bit registers and instructions)
 = 00000000		      C __UseY			EQU				0									; Use AVX2 processor features (256 bit registers and instructions)
 = 00000000		      C __UseX			EQU				0									; Use SIMD/SSE processor features (128 bit registers and instructions)
 = 00000000		      C __UseQ			EQU				0									; Do not use extensions, use standard x64 bit registers and instructions
			      C ;
 = 00000000		      C __CheckAlign	EQU				0									; User is expected to pass arguments aligned on 64 byte boundaries, 
			      C 																	; This setting enforces that with a check. It should not be necessary, but included to help debugging
			      C 
			      C ;           Some coding shortcuts
 = ZMMWORD PTR		      C ZM_PTR			EQU				ZMMWORD PTR
 = YMMWORD PTR		      C YM_PTR			EQU				YMMWORD PTR
 = XMMWORD PTR		      C XM_PTR			EQU				XMMWORD PTR
 = QWORD PTR		      C Q_PTR			EQU				QWORD PTR
 = DWORD PTR		      C D_PTR			EQU				DWORD PTR
 = WORD PTR		      C W_PTR			EQU				WORD PTR
 = BYTE PTR		      C B_PTR			EQU				BYTE PTR
 = DWORD BCST		      C m32BCST			EQU				DWORD BCST
 = QWORD BCST		      C m64BCST			EQU				QWORD BCST
			      C 
			      C ;			mask codes (for compares using instructions like VPCMPUQ)
 = 00000000		      C CPEQ			EQU				0
 = 00000001		      C CPLT			EQU				1
 = 00000002		      C CPLE			EQU				2
 = 00000003		      C CPFALSE			EQU				3
 = 00000004		      C CPNE			EQU				4
 = 00000005		      C CPGE			EQU				5
 = 00000006		      C CPGT			EQU				6
 = 00000007		      C CPTRUE			EQU				7
			      C 
			      C ;			Mask values (for k reg) used to select particulare QWORDS from X, Y, or Z simd regs
 = 00000001		      C MaskBit0		EQU				B_PTR [ 00000001b ]
 = 00000002		      C MaskBit1		EQU				B_PTR [ 00000010b ]
 = 00000004		      C MaskBit2		EQU				B_PTR [ 00000100b ]
 = 00000008		      C MaskBit3		EQU				B_PTR [ 00001000b ]
 = 00000010		      C MaskBit4		EQU				B_PTR [ 00010000b ]
 = 00000020		      C MaskBit5		EQU				B_PTR [ 00100000b ]
 = 00000040		      C MaskBit6		EQU				B_PTR [ 01000000b ]
 = 00000080		      C MaskBit7		EQU				B_PTR [ 10000000b ]
			      C 
 = 			      C Mask20			EQU
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ; return (if any) is in EAX
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C 
			      C ;===========================================================================================
			      C ;          Local macros
			      C ;===========================================================================================
			      C 
			      C ;
			      C ;			Test passed variable addresses for 64 byte alignment
			      C ;			Note: Better performance if this is off, but for debugging, maybe have it on
			      C ;
			      C 
			      C CheckAlign		MACRO			Raddr
			      C 				LOCAL			ok
			      C 	IF	__CheckAlign
			      C 				TEST			Raddr, 63							; Is specified param aligned 64?
			      C 				JZ				ok									; Yes, passes test, continue
			      C 				INT				0									; No, fails, break (can substitute other exception handling)
			      C ok:
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C MemConstants	MACRO
			      C ;		Return codes commonly used.			
			      C ret0			DD				0								
			      C ret1			DD				1
			      C ret_1			DD				-1
			      C ;		Masks commonly used
			      C mskAll8			DB				255
			      C mskB0			DB				1
			      C mskB1			DB				2
			      C mskB2			DB				4
			      C mskB3			DB				8
			      C mskB4			DB				16
			      C mskB5			DB				32
			      C mskB6			DB				64
			      C mskB7			DB				128
			      C mskHex100		DD				0100h
			      C 				ENDM
			      C 
			      C ;
			      C ;			Zero a 512 bit destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Zero512			MACRO			dest
			      C 				CheckAlign		dest
			      C 	IF	__UseZ
			      C 				VPXORQ			ZMM31, ZMM31, ZMM31
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VPXORQ			YMM4, YMM4, YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM4
			      C 	ELSEIF	__UseX
			      C 				PXOR			XMM4, XMM4
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM4			
			      C 	ELSE
			      C 				XOR				RAX, RAX
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C 
			      C ;
			      C ;			Copy a 512 bit source to destination, conditional assembly based on configuration parameters
			      C ;
			      C 
			      C Copy512			MACRO			dest, src
			      C 				CheckAlign		dest
			      C 				CheckAlign		src
			      C 	IF	__UseZ
			      C 				VMOVDQA64		ZMM31, ZM_PTR [ src ]
			      C 				VMOVDQA64		ZM_PTR [ dest ], ZMM31
			      C 	ELSEIF	__UseY
			      C 				VMOVDQA64		YMM4, YM_PTR [ src + 0 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			      C 				VMOVDQA64		YMM5, YM_PTR [ src + 4 * 8 ]
			      C 				VMOVDQA64		YM_PTR [ dest + 4 * 8 ], YMM5
			      C 	ELSEIF	__UseX
			      C 				MOVDQA			XMM4, XM_PTR [ src + 0 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 0 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 2 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 2 * 8 ], XMM3
			      C 				MOVDQA			XMM4, XM_PTR [ src + 4 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 4 * 8 ], XMM4
			      C 				MOVDQA			XMM3, XM_PTR [ src + 6 * 8 ]
			      C 				MOVDQA			XM_PTR [ dest + 6 * 8 ], XMM3
			      C 	ELSE
			      C 				MOV				RAX, [ src + 0 * 8 ]
			      C 				MOV				[ dest + 0 * 8 ], RAX
			      C 				MOV				RAX, [ src + 1 * 8 ]
			      C 				MOV				[ dest + 1 * 8 ], RAX
			      C 				MOV				RAX, [ src + 2 * 8 ]
			      C 				MOV				[ dest + 2 * 8 ], RAX
			      C 				MOV				RAX, [ src + 3 * 8 ]
			      C 				MOV				[ dest + 3 * 8 ], RAX
			      C 				MOV				RAX, [ src + 4 * 8 ]
			      C 				MOV				[ dest + 4 * 8 ], RAX
			      C 				MOV				RAX, [ src + 5 * 8 ]
			      C 				MOV				[ dest + 5 * 8 ], RAX
			      C 				MOV				RAX, [ src + 6 * 8 ]
			      C 				MOV				[ dest + 6 * 8 ], RAX
			      C 				MOV				RAX, [ src + 7 * 8 ]
			      C 				MOV				[ dest + 7 * 8 ], RAX
			      C 	ENDIF
			      C 				ENDM
			      C 
			      C ;
			      C ;			Get a GP reg QWORD from within a Z register as specified by mask
			      C ;			Note: RAX, ZMM0 and k1 are used and not restored
			      C ;			Example usage: GetZatIdx R11, ZMM1, MaskBit2 or SetZatIdx ZMM1, R12, [ R9 ]  (where R9 is a bit mask, not an integer index)
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C GetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX,  mask
			      C 				KMOVB			k1, RAX
			      C 				VPCOMPRESSQ		ZMM0 {k1}{z}, src
			      C 				VMOVQ			dest, XMM0
			      C 				ENDM
			      C 
			      C ;
			      C ;			Set a GP Reg QWORD within a Z register as specified by mask
			      C ;			Note: RAX and k1 are used and not restored
			      C ;			Example usage: SetZatIdx ZMM1, R8, MaskBit2
			      C ;			Note: These are req to reg ops; no memory fetches (other than instructions from pipeline)
			      C ;
			      C 
			      C SetZatMask		MACRO			dest, src, mask
			      C 				LEA				RAX, mask
			      C 				KMOVB			k1, RAX
			      C 				VPBROADCASTQ 	dest {k1}, src
			      C 				ENDM
			      C ENDIF
			      C 
								INCLUDE			ui512bMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512bMacros
			      C ;
			      C ;			File:			ui512bMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			June 11, 2024
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;				The basic operations: zero, copy, compare, add, subtract.
			      C ;               Other optional modules provide bit ops and multiply / divide.
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;				This module is very light-weight (less than 1K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;				Use for private (hobbyist), or instructional,
			      C ;				or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not,
			      C ;               least significant bit and most significant bit.
			      C ;
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C 
			      C IFNDEF						ui512bMacros_INC
 = 1			      C ui512bMacros_INC EQU		<1>
			      C ;           header file equivalent extern declarations
			      C ;			EXTERN "C" signatures (from ui512b.asm)
			      C 
			      C ;   // void shr_u ( u64* destination, u64* source, u32 bits_to_shift )
			      C ;   // shift supplied source 512bit (8 QWORDS) right, put in destination
			      C EXTERNDEF	shr_u:PROC
			      C 
			      C ;   // void shl_u ( u64* destination, u64* source, u16 bits_to_shift );
			      C ;   // shift supplied source 512bit (8 QWORDS) left, put in destination
			      C EXTERNDEF	shl_u:PROC
			      C 
			      C ;   // void and_u ( u64* destination, u64* lh_op, u64* rh_op );
			      C ;   // logical 'AND' bits in lh_op, rh_op, put result in destination
			      C EXTERNDEF	and_u:PROC
			      C 
			      C ;   // logical 'OR' bits in lh_op, rh_op, put result in destination
			      C ;   // void or_u( u64* destination, u64* lh_op, u64* rh_op);
			      C EXTERNDEF	or_u:PROC
			      C 
			      C ;   // logical 'NOT' bits in source, put result in destination
			      C ;	// void not_u( u64* destination, u64* source);
			      C EXTERNDEF	not_u:PROC
			      C 
			      C ;   // find most significant bit in supplied source 512bit (8 QWORDS)
			      C ;	// s16 msb_u( u64* );
			      C ;   // returns: -1 if no most significant bit, bit number otherwise, bits numbered 0 to 511 inclusive
			      C EXTERNDEF	msb_u:PROC
			      C 
			      C ;   // find least significant bit in supplied source 512bit (8 QWORDS)
			      C ;	// s16 lsb_u( u64* );
			      C ;   // returns: -1 if no least significant bit, bit number otherwise, bits numbered 0 to 511 inclusive
			      C EXTERNDEF	lsb_u:PROC
			      C 
			      C ENDIF
			      C 
								INCLUDE			ui512mdMacros.inc
			      C .nolist
			      C ;
			      C ;			ui512mdMacros
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;			File:			ui512mdMacros.inc
			      C ;			Author:			John G. Lynch
			      C ;			Legal:			Copyright @2024, per MIT License below
			      C ;			Date:			June 20, 2024
			      C 
			      C ;
			      C ;			Notes:
			      C ;				ui512 is a small project to provide basic operations for a variable type of unsigned 512 bit integer.
			      C ;
			      C ;				ui512a provides basic operations: zero, copy, compare, add, subtract.
			      C ;				ui512b provides basic bit-oriented operations: shift left, shift right, and, or, not, least significant bit and most significant bit.
			      C ;               ui512md provides multiply and divide.
			      C ;
			      C ;				It is written in assembly language, using the MASM (ml64) assembler provided as an option within Visual Studio.
			      C ;				(currently using VS Community 2022 17.9.6)
			      C ;
			      C ;				It provides external signatures that allow linkage to C and C++ programs,
			      C ;				where a shell/wrapper could encapsulate the methods as part of an object.
			      C ;
			      C ;				It has assembly time options directing the use of Intel processor extensions: AVX4, AVX2, SIMD, or none:
			      C ;				(Z (512), Y (256), or X (128) registers, or regular Q (64bit)).
			      C ;
			      C ;				If processor extensions are used, the caller must align the variables declared and passed
			      C ;				on the appropriate byte boundary (e.g. alignas 64 for 512)
			      C ;
			      C ;				This module is very light-weight (less than 1K bytes) and relatively fast,
			      C ;				but is not intended for all processor types or all environments. 
			      C ;
			      C ;				Use for private (hobbyist), or instructional, or as an example for more ambitious projects is all it is meant to be.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;
			      C ;			MIT License
			      C ;
			      C ;			Copyright (c) 2024 John G. Lynch
			      C ;
			      C ;				Permission is hereby granted, free of charge, to any person obtaining a copy
			      C ;				of this software and associated documentation files (the "Software"), to deal
			      C ;				in the Software without restriction, including without limitation the rights
			      C ;				to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
			      C ;				copies of the Software, and to permit persons to whom the Software is
			      C ;				furnished to do so, subject to the following conditions:
			      C ;
			      C ;				The above copyright notice and this permission notice shall be included in all
			      C ;				copies or substantial portions of the Software.
			      C ;
			      C ;				THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
			      C ;				IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
			      C ;				FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
			      C ;				AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
			      C ;				LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
			      C ;				OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
			      C ;				SOFTWARE.
			      C ;
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C IFNDEF						ui512mdMacros_INC
 = 1			      C ui512mdMacros_INC EQU		<1>
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;			signatures (from ui512md.asm)
			      C 
			      C ;			mult_uT64		-	multiply 512 bit multiplicand by 64 bit multiplier, giving 512 product, 64 bit overflow
			      C ;			Prototype:		-	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
			      C EXTERNDEF	mult_uT64:PROC	;	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
			      C 
			      C ;			mult_u			-	multiply 512 multiplicand by 512 multiplier, giving 512 product, overflow
			      C ;			Prototype:		-	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
			      C EXTERNDEF	mult_u:PROC		;	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
			      C 
			      C ;			div_uT64		-	divide 512 bit dividend by 64 bit bit divisor, giving 512 bit quotient and 64 bit remainder
			      C ;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64 divisor,);
			      C EXTERNDEF	div_uT64:PROC	;	s16 div_uT64( u64* quotient, u64* remainder, u64* dividend, u64 divisor);
			      C 
			      C ;			div_u			-	divide 512 bit dividend by 512 bit divisor, giving 512 bit quotient and remainder
			      C ;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
			      C EXTERNDEF	div_u:PROC		;	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C 
			      C CreateFrame	MACRO			argsize, argsavename
			      C ;
			      C ;			set up frame to save regs, and to create aligned working memory for scratch variables
			      C ;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			      C ;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			      C ;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			      C ;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			      C ;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			      C ;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			      C ;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			      C ;			example:
			      C ;
			      C ;somename	PROC
			      C ;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			      C ;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			      C ;			LOCAL		some local variable declarions, some more, and some more
			      C ;			LOCAL		and some more
			      C ;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			      C ;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			      C ;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			      C ;
			      C ;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			      C ;
			      C 			PUSH			RBP
			      C 			MOV				RBP, RSP
			      C 			ADD				RSP, -(( argsize / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
			      C 			MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
			      C 			AND				RSP, RAX
			      C 			AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
			      C 			XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
			      C 			MOV				argsavename, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
			      C 			ENDM
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C 
			      C 
			      C ReleaseFrame MACRO			argsavename
			      C ;			release memory set up by createframe macro
			      C ;			restores RSP, and RBP to as-called values
			      C ;			after these instructions are executed, no LOCAL variables can be accessed
			      C ;			This needs to be done to restore the stack correctly, but can be done only once
			      C ;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
			      C 			MOV				RBP, argsavename
			      C 			LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
			      C 			ENDM
			      C 
			      C ;--------------------------------------------------------------------------------------------------------------------------------------------------------------
			      C ;==========================================================================================
			      C ;           Notes on x64 calling conventions        aka "fast call"
			      C ; ref: https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170
			      C ; The first four parameters are passed in registers: RCX, RDX, R8, R9 if integer or address
			      C ; if floating point XMM0L, XMM1L, XMM2L, XMM3L
			      C ;===========================================================================================
			      C ;
			      C ;===========================================================================================
			      C ; RAX, RCX, RDX, R8, R9, R10, R11 are considered volatile, and do not need to be saved
			      C ; XMM0, YMM0, ZMM0 and  ..1, ..2, ..3, ..4, and ..5 are considered volatile,
			      C ;	and do not need to be saved
			      C ;  ZMM16 to ZMM31: volatile, also do not need to be zeroed to resume full clock speeds
			      C ;
			      C ; R12, R13, R14, R15, RDI, RSI, RBX, RBP, RSP are non-volatile and if used, must be restored
			      C ; XMM, YMM, and ZMM ..6 thru 15 are non-volatile and if used, must be restored
			      C ;
			      C ; A "leaf" function is one that does not call and does not change non volatile registers
			      C ; leaf functionss therefore do not need frame, prolog or epilog
			      C ;
			      C ;===========================================================================================
			      C 
			      C ENDIF
			      C 

								OPTION			casemap:none
 00000000			.CODE			ui512md
								OPTION			PROLOGUE:none
								OPTION			EPILOGUE:none

								MemConstants
			     1	;		Return codes commonly used.			
 00000000 00000000	     1	ret0			DD				0								
 00000004 00000001	     1	ret1			DD				1
 00000008 FFFFFFFF	     1	ret_1			DD				-1
			     1	;		Masks commonly used
 0000000C FF		     1	mskAll8			DB				255
 0000000D 01		     1	mskB0			DB				1
 0000000E 02		     1	mskB1			DB				2
 0000000F 04		     1	mskB2			DB				4
 00000010 08		     1	mskB3			DB				8
 00000011 10		     1	mskB4			DB				16
 00000012 20		     1	mskB5			DB				32
 00000013 40		     1	mskB6			DB				64
 00000014 80		     1	mskB7			DB				128
 00000015 00000100	     1	mskHex100		DD				0100h

				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		mult_u:PROC					; void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier)
				;			mult_u			-	multiply 512 multiplicand by 512 multiplier, giving 512 product, overflow
				;			Prototype:		-	void mult_u( u64* product, u64* overflow, u64* multiplicand, u64* multiplier);
				;			product			-	Address of 8 QWORDS to store resulting product (in RCX)
				;			overflow		-	Address of 8 QWORDS to store resulting overflow (in RDX)
				;			multiplicand	-	Address of 8 QWORDS multiplicand (in R8)
				;			multiplier		-	Address of 8 QWORDS multiplier (in R9)
				;			returns			-	nothing (0)

 00000019			mult_u			PROC			PUBLIC
								LOCAL			padding1 [ 8 ] : QWORD
								LOCAL			product [ 16 ] : QWORD
								LOCAL			savedRBP : QWORD
								LOCAL			savedRCX : QWORD, savedRDX : QWORD, savedR10 : QWORD, savedR11 : QWORD, savedR12 : QWORD
								LOCAL			plierl : WORD						; low limit index of of multiplier (7 - first non-zero)
								LOCAL			candl : WORD						; low limit index of multiplicand
								LOCAL			padding2 [ 16 ] : QWORD
 = padding2 + 64 - padding1	mult_u_ofs		EQU				padding2 + 64 - padding1			; offset is the size of the local memmory declarations

								CreateFrame		220h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 00000019  55		     1				PUSH			RBP
 0000001A  48/ 8B EC	     1				MOV				RBP, RSP
 0000001D  48/ 81 C4	     1				ADD				RSP, -(( 220h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFD9C
 00000024  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 0000002B  48/ 23 E0	     1				AND				RSP, RAX
 0000002E  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 00000031  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 00000033  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFF38
 0000003A  48/ 89 8D						MOV				savedRCX, RCX
	   FFFFFF30
 00000041  48/ 89 95						MOV				savedRDX, RDX
	   FFFFFF28
 00000048  4C/ 89 95						MOV				savedR10, R10
	   FFFFFF20
 0000004F  4C/ 89 9D						MOV				savedR11, R11
	   FFFFFF18
 00000056  4C/ 89 A5						MOV				savedR12, R12
	   FFFFFF10

								CheckAlign		RCX									; (out) Product
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			RCX, 63							; Is specified param aligned 64?
			     1					JZ				??0000									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0000:
			     1		ENDIF
								CheckAlign		RDX									; (out) Overflow
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			RDX, 63							; Is specified param aligned 64?
			     1					JZ				??0001									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0001:
			     1		ENDIF
								CheckAlign		R8									; (in) Multiplicand
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			R8, 63							; Is specified param aligned 64?
			     1					JZ				??0002									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0002:
			     1		ENDIF
								CheckAlign		R9									; (in) Multiplier
			     1					LOCAL			ok
			     1		IF	__CheckAlign
			     1					TEST			R9, 63							; Is specified param aligned 64?
			     1					JZ				??0003									; Yes, passes test, continue
			     1					INT				0									; No, fails, break (can substitute other exception handling)
			     1	??0003:
			     1		ENDIF

				; Examine multiplicand, save dimensions, handle edge cases of zero or one
 0000005D  49/ 8B C8						MOV				RCX, R8								; examine multiplicand
 00000060  E8 00000000 E					CALL			msb_u
 00000065  83 F8 FF						CMP				EAX, -1								; multiplicand = 0? exit with product = 0
 00000068  0F 84 00000129					JE				@@zeroandexit
 0000006E  83 F8 00						CMP				EAX, 0								; multiplicand = 1?	exit with product = multiplier
 00000071  49/ 8B D1						MOV				RDX, R9								; address of multiplier (to be copied to product)
 00000074  0F 84 00000145					JE				@@copyandexit
 0000007A  66| C1 E8 06						SHR				AX, 6								; divide by 64 to get Nr words
 0000007E  48/ C7 C1						MOV				RCX, 7
	   00000007
 00000085  66| 2B C8						SUB				CX, AX								; subtract from 7 to get starting (high order) begining index
 00000088  66| 89 8D						MOV				candl, CX							; save off multiplicand index lower limit (eliminate multiplying leading zero words)
	   FFFFFF0C

				; Examine multiplier, save dimensions, handle edge cases of zero or one
 0000008F  49/ 8B C9						MOV				RCX, R9								; examine multiplier
 00000092  E8 00000000 E					CALL			msb_u
 00000097  83 F8 FF						CMP				EAX, -1								; multiplier = 0? exit with product = 0
 0000009A  0F 84 000000F7					JE				@@zeroandexit
 000000A0  83 F8 00						CMP				EAX, 0								; multiplier = 1? exit with product = multiplicand
 000000A3  49/ 8B D0						MOV				RDX, R8								; address of multiplicand (to be copied to product)
 000000A6  0F 84 00000113					JE				@@copyandexit
 000000AC  66| C1 E8 06						SHR				AX, 6
 000000B0  48/ C7 C1						MOV				RCX, 7
	   00000007
 000000B7  66| 2B C8						SUB				CX, AX
 000000BA  66| 89 8D						MOV				plierl, CX							; save off multiplier index lower limit (eliminate multiplying leading zero words)
	   FFFFFF0E

				; In heap / frame / stack reserved memory, clear 16 word area for overflow/product; set up indexes for loop
 000000C1  48/ 8D 8D						LEA				RCX, product [ 0 ]
	   FFFFFF40
								Zero512			RCX									; clear working copy of overflow, need to start as zero, results are added in
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0004									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0004:
			     2		ENDIF
			     1		IF	__UseZ
 000000C8  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000000CE  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000000D4  48/ 8D 4D 80						LEA				RCX, product[ 8 * 8 ]
								Zero512			RCX									; clear working copy of product (they need to be contiguous, so using working copy, not callers)
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0005									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0005:
			     2		ENDIF
			     1		IF	__UseZ
 000000D8  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000000DE  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000000E4  49/ C7 C3						MOV				R11, 7								; index for multiplier (reduced until less then saved plierl)
	   00000007
 000000EB  49/ C7 C4						MOV				R12, 7								; index for multiplicand (reduced until less than saved candl)
	   00000007

				; multiply loop: an outer loop for each non-zero word of multiplicand, with an inner loop for each non-zero word of multiplier
 000000F2			@@multloop:
 000000F2  4D/ 8B D3						MOV				R10, R11							; R10 holds index for overflow / product work area (results)
 000000F5  4D/ 03 D4						ADD				R10, R12
 000000F8  49/ FF C2						INC				R10									; index for product/overflow 
 000000FB  4B/ 8B 04 E0						MOV				RAX, [ R8 ] + [ R12 * 8 ]			; get qword of multiplicand
 000000FF  4B/ F7 24 D9						MUL				Q_PTR [ R9 ] + [ R11 * 8 ]			; multiply by qword of multiplier
 00000103  4A/ 01 84 D5						ADD				product [ R10 * 8 ], RAX
	   FFFFFF40
 0000010B  49/ FF CA						DEC				R10									; preserves carry flag
 0000010E			@@:
 0000010E  4A/ 11 94 D5						ADC				product [ R10 * 8 ], RDX
	   FFFFFF40
 00000116  48/ C7 C2						MOV				RDX, 0								; again, preserves carry flag
	   00000000
 0000011D  73 05						JNC				@F
 0000011F  49/ FF CA						DEC				R10
 00000122  7D EA						JGE				@B
 00000124			@@:																	; next word of multiplicand
 00000124  49/ FF CC						DEC				R12
 00000127  66| 44/ 3B A5					CMP				R12W, candl
	   FFFFFF0C
 0000012F  7D C1						JGE				@@multloop
 00000131  49/ C7 C4						MOV				R12, 7
	   00000007
 00000138  49/ FF CB						DEC				R11
 0000013B  66| 44/ 3B 9D					CMP				R11W, plierl
	   FFFFFF0E
 00000143  7D AD						JGE				@@multloop							; next word of multiplier

				; copy working product/overflow to callers product / overflow
 00000145  48/ 8B 8D						MOV				RCX, savedRCX
	   FFFFFF30
 0000014C  48/ 8D 55 80						LEA				RDX, product [ 8 * 8 ]
								Copy512			RCX, RDX						; copy working product to callers product
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0006									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0006:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0007									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0007:
			     2		ENDIF
			     1		IF	__UseZ
 00000150  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 00000156  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000015C  48/ 8B 8D						MOV				RCX, savedRDX
	   FFFFFF28
 00000163  48/ 8D 95						LEA				RDX, product [ 0 ]
	   FFFFFF40
								Copy512			RCX, RDX						; copy working overflow to callers overflow
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0008									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0008:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0009									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0009:
			     2		ENDIF
			     1		IF	__UseZ
 0000016A  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 00000170  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF

				; restore regs, release frame, return
 00000176			@@exit:			
 00000176  4C/ 8B 95						MOV				R10, savedR10
	   FFFFFF20
 0000017D  4C/ 8B 9D						MOV				R11, savedR11
	   FFFFFF18
 00000184  4C/ 8B A5						MOV				R12, savedR12					; restore any non-volitile regs used
	   FFFFFF10
								ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 0000018B  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFF38
 00000192  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 00000193  48/ 33 C0						XOR				RAX, RAX						; return zero
								RET
 00000196  C3		   *	    ret    00000h

				; zero callers product and overflow
 00000197			@@zeroandexit:
 00000197  48/ 8B 8D						MOV				RCX, savedRCX					; reload address of callers product
	   FFFFFF30
								Zero512			RCX								; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000A									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000A:
			     2		ENDIF
			     1		IF	__UseZ
 0000019E  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001A4  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001AA  48/ 8B 8D						MOV				RCX, savedRDX					; reload address of caller overflow
	   FFFFFF28
								Zero512			RCX								; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000B									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000B:
			     2		ENDIF
			     1		IF	__UseZ
 000001B1  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001B7  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001BD  EB B7						JMP				@@exit

				; multiplying by 1: zero overflow, copy the non-one to the product
 000001BF			@@copyandexit:
 000001BF  48/ 8B 8D						MOV				RCX, savedRDX					; address of passed overflow
	   FFFFFF28
								Zero512			RCX 							; zero it
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000C									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000C:
			     2		ENDIF
			     1		IF	__UseZ
 000001C6  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 000001CC  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001D2  48/ 8B 8D						MOV				RCX, savedRCX					; copy (whichever: multiplier or multiplicand) to callers product
	   FFFFFF30
								Copy512			RCX, RDX						; RDX "passed" here from whomever jumped here (either multiplier, or multiplicand in RDX)
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000D									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000D:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??000E									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000E:
			     2		ENDIF
			     1		IF	__UseZ
 000001D9  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 000001DF  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000001E5  EB 8F						JMP				@@exit							; and exit
 000001E7			mult_u			ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		mult_uT64:PROC				;	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
				;			mult_uT64		-	multiply 512 bit multiplicand by 64 bit multiplier, giving 512 product, 64 bit overflow
				;			Prototype:		-	void mult_uT64( u64* product, u64* overflow, u64* multiplicand, u64 multiplier);
				;			product			-	Address of 8 QWORDS to store resulting product (in RCX)
				;			overflow		-	Address of QWORD for resulting overflow (in RDX)
				;			multiplicand	-	Address of 8 QWORDS multiplicand (in R8)
				;			multiplier		-	multiplier QWORD (in R9)
				;			returns			-	nothing (0)

							OPTION			PROLOGUE:none
							OPTION			EPILOGUE:none
 000001E7			mult_uT64	PROC			PUBLIC

							LOCAL			padding1 [ 8 ] :QWORD
							LOCAL			product [ 8 ] :QWORD
							LOCAL			savedRBP :QWORD, savedRCX :QWORD, savedRDX :QWORD 
							LOCAL			overflow :QWORD
							LOCAL			padding2 [ 8 ] :QWORD
 = padding2 + 64 - padding1	mult64_oset	EQU				padding2 + 64 - padding1

							CreateFrame		120h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 000001E7  55		     1				PUSH			RBP
 000001E8  48/ 8B EC	     1				MOV				RBP, RSP
 000001EB  48/ 81 C4	     1				ADD				RSP, -(( 120h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFEBC
 000001F2  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 000001F9  48/ 23 E0	     1				AND				RSP, RAX
 000001FC  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 000001FF  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 00000201  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFF78
 00000208  48/ 89 8D					MOV				savedRCX, RCX
	   FFFFFF70
 0000020F  48/ 89 95					MOV				savedRDX, RDX
	   FFFFFF68

 00000216  48/ 8D 4D 80					LEA				RCX, product
							Zero512			RCX								; clear working copy of product and overflow
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??000F									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??000F:
			     2		ENDIF
			     1		IF	__UseZ
 0000021A  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000220  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 00000226  48/ 33 C0					XOR				RAX, RAX
 00000229  48/ 89 85					MOV				overflow, RAX
	   FFFFFF60
							;
					
 00000230  49/ 8B 40 38					MOV				RAX, [ R8 + 7 * 8 ]			; multiplicand 8th qword
 00000234  49/ F7 E1					MUL				R9								; times multiplier
 00000237  48/ 01 45 B8					ADD				product [ 7 * 8 ], RAX			; to working product 8th word
 0000023B  48/ 11 55 B0					ADC				product [ 6 * 8 ], RDX			; 'overflow' to 7th qword of working product
 0000023F  49/ 8B 40 30					MOV				RAX, [ R8 + 6 * 8 ]			; 7th
 00000243  49/ F7 E1					MUL				R9
 00000246  48/ 01 45 B0					ADD				product [ 6 * 8 ], RAX			
 0000024A  48/ 11 55 A8					ADC				product [ 5 * 8 ], RDX
 0000024E  49/ 8B 40 28					MOV				RAX, [ R8 + 5 * 8 ]			; 6th
 00000252  49/ F7 E1					MUL				R9
 00000255  48/ 01 45 A8					ADD				product [ 5 * 8 ], RAX			
 00000259  48/ 11 55 A0					ADC				product [ 4 * 8 ], RDX
 0000025D  49/ 8B 40 20					MOV				RAX, [ R8 + 4 * 8 ]			; 5th
 00000261  49/ F7 E1					MUL				R9
 00000264  48/ 01 45 A0					ADD				product [ 4 * 8 ], RAX			
 00000268  48/ 11 55 98					ADC				product [ 3 * 8 ], RDX
 0000026C  49/ 8B 40 18					MOV				RAX, [ R8 + 3 * 8 ]			; 4th
 00000270  49/ F7 E1					MUL				R9
 00000273  48/ 01 45 98					ADD				product [ 3 * 8 ], RAX			
 00000277  48/ 11 55 90					ADC				product [ 2 * 8 ], RDX
 0000027B  49/ 8B 40 10					MOV				RAX, [ R8 + 2 * 8 ]			; 3rd
 0000027F  49/ F7 E1					MUL				R9
 00000282  48/ 01 45 90					ADD				product [ 2 * 8 ], RAX			
 00000286  48/ 11 55 88					ADC				product [ 1 * 8 ], RDX
 0000028A  49/ 8B 40 08					MOV				RAX, [ R8 + 1 * 8 ]			; 2nd
 0000028E  49/ F7 E1					MUL				R9
 00000291  48/ 01 45 88					ADD				product [ 1 * 8 ], RAX			
 00000295  48/ 11 55 80					ADC				product [ 0 * 8 ], RDX
 00000299  49/ 8B 00					MOV				RAX, [ R8 + 0 * 8 ]			; 1st
 0000029C  49/ F7 E1					MUL				R9
 0000029F  48/ 01 45 80					ADD				product [ 0 * 8 ], RAX
 000002A3  48/ 11 95					ADC				overflow, RDX					; last qword overflow is also the operation overflow
	   FFFFFF60

 000002AA  48/ 8B 8D					MOV				RCX, savedRCX					; send results back to caller
	   FFFFFF70
 000002B1  48/ 8D 55 80					LEA				RDX, product
							Copy512			RCX, RDX
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0010									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0010:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0011									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0011:
			     2		ENDIF
			     1		IF	__UseZ
 000002B5  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 000002BB  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000002C1  48/ 8B 85					MOV				RAX, overflow
	   FFFFFF60
 000002C8  48/ 8B 95					MOV				RDX, savedRDX
	   FFFFFF68
 000002CF  48/ 89 02					MOV				Q_PTR [ RDX ], RAX

				;			release frame, return
							ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 000002D2  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFF78
 000002D9  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 000002DA  48/ 33 C0					XOR				RAX, RAX						; return zero
							RET
 000002DD  C3		   *	    ret    00000h
 000002DE			mult_uT64	ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		div_u:PROC					; s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor)
				;			div_u			-	divide 512 bit dividend by 512 bit divisor, giving 512 bit quotient and remainder
				;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64* divisor);
				;			quotient		-	Address of 8 QWORDS to store resulting quotient (in RCX)
				;			remainder		-	Address of 8 QWORDs for resulting remainder (in RDX)
				;			dividend		-	Address of 8 QWORDS dividend (in R8)
				;			divisor			-	Address of 8 QWORDs divisor (in R9)
				;			returns			-	0 for success, -1 for attempt to divide by zero

							OPTION			PROLOGUE:none
							OPTION			EPILOGUE:none
 000002DE			div_u		PROC			PUBLIC

							LOCAL			padding1 [ 8 ] : QWORD
							LOCAL			currnumerator [ 16 ] : QWORD
							LOCAL			qdiv [ 8 ] : QWORD			
							LOCAL			quotient [ 8 ] : QWORD
							LOCAL			normdivisor [ 8 ] : QWORD
							LOCAL			savedRBP : QWORD
							LOCAL			savedRCX : QWORD, savedRDX : QWORD, savedR8 : QWORD, savedR9 : QWORD
							LOCAL			savedR10 : QWORD, savedR11 : QWORD, savedR12 : QWORD
							LOCAL			qHat : QWORD
							LOCAL			rHat : QWORD
							LOCAL			qovf : QWORD
							LOCAL			currenumbegin : QWORD
							LOCAL			normf : WORD
							LOCAL			limEnumIdx : WORD
							LOCAL			jIdx: WORD
							LOCAL			dimM: WORD
							LOCAL			dimN: WORD
							
							LOCAL			padding2 [ 16 ] : QWORD
 = padding2 + 64 - padding1	div_oset	EQU				padding2 + 64 - padding1

							CreateFrame		320h, savedRBP
			     1	;
			     1	;			set up frame to save regs, and to create aligned working memory for scratch variables
			     1	;			argsize is the amount of space to be made on on the stack for locals and padding (at least 40h on each end)
			     1	;			argsavename is the name of the variable, within the LOCAL declarations, QWORD, for the RBP to be saved, and restored from
			     1	;			No prologue, epilogue should be used. LOCAL declarations immediately after PROC statement, then this macro
			     1	;			Note: LOCAL variables will START on a 64 byte aligned address space. Your order and sizes of your variables will be in sequence as declared
			     1	;			and thus provide no assurance of alignment other than what your declarations imply. In other words, declaring a byte var at the beginning
			     1	;			throws everyting after that off by a byte. OK, not exacly, the asm will align by data type (eg, QWORD on 8 byte), but there is no way to get back
			     1	;			to 64 byte alignment, so declare those first, then QWORD, then DWORD, etc. Or, count your declares such that you get what/where you want.
			     1	;			example:
			     1	;
			     1	;somename	PROC
			     1	;			LOCAL		padding1[8]:QWORD				; warning: do not touch, initialize, or use padding. (on either end)
			     1	;			LOCAL		somelocal:ZMMWORD				; a 512 bit, 64 byte aligned var, ready for aligned load/store into ZMM (AVX2) register
			     1	;			LOCAL		some local variable declarions, some more, and some more
			     1	;			LOCAL		and some more
			     1	;			LOCAL		savedRBP:QWORD					; you might have other reg save space as well
			     1	;			LOCAL		padding2[8]:QWORD				; after your return statement, before ENDP, might LEA padding1 and padding2 to eliminate warning (unreferenced variables)
			     1	;			CREATEFRAME 200h, savedRBP (200h assumes 118h in those "some local variable declarations", adjust as necessary)
			     1	;
			     1	;			Use only one return from the PROC, and immediately before return, use RELEASEFRAME macro, giving name of where RBP is saved
			     1	;
 000002DE  55		     1				PUSH			RBP
 000002DF  48/ 8B EC	     1				MOV				RBP, RSP
 000002E2  48/ 81 C4	     1				ADD				RSP, -(( 320h / 8 ) * ( 8 + 1 )); make gap between old stack pointer and current stack pointer for use as "LOCAL", adjust size if changes made to locals
	   FFFFFC7C
 000002E9  48/ C7 C0	     1				MOV				RAX, -64					; Round it (down), to make it, and local vars, align on 64 byte address (necessary for aligned ZMM load/store)
	   FFFFFFC0
 000002F0  48/ 23 E0	     1				AND				RSP, RAX
 000002F3  48/ 23 C5	     1				AND				RAX, RBP					; note: "padding" variables must not be used. They are in areas where we have just rounded down, or in stack space for those we call
 000002F6  48/ 95	     1				XCHG			RAX, RBP					; RBP now points to top of gap between old stack pointer and current stack pointer, aligned on 64
 000002F8  48/ 89 85	     1				MOV				savedRBP, RAX			; LOCAL variables now usable, using negative offsets from the new RBP value. Must restore RBP, RSP at exit (Use RELEASEFRAME)
	   FFFFFE78
 000002FF  48/ 89 8D					MOV				savedRCX, RCX
	   FFFFFE70
 00000306  48/ 89 95					MOV				savedRDX, RDX
	   FFFFFE68
 0000030D  4C/ 89 85					MOV				savedR8, R8
	   FFFFFE60
 00000314  4C/ 89 8D					MOV				savedR9, R9
	   FFFFFE58
 0000031B  4C/ 89 95					MOV				savedR10, R10
	   FFFFFE50
 00000322  4C/ 89 9D					MOV				savedR11, R11
	   FFFFFE48
 00000329  4C/ 89 A5					MOV				savedR12, R12
	   FFFFFE40
							;
							Zero512			RCX							; zero callers quotient
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0012									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0012:
			     2		ENDIF
			     1		IF	__UseZ
 00000330  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000336  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000033C  48/ 8B CA					MOV				RCX, RDX
							Zero512			RCX							; zero callers remainder
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0013									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0013:
			     2		ENDIF
			     1		IF	__UseZ
 0000033F  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000345  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000034B  48/ 8D 8D					LEA				RCX, quotient
	   FFFFFEC0
							Zero512			RCX							; zero working quotient
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0014									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0014:
			     2		ENDIF
			     1		IF	__UseZ
 00000352  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000358  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
							;
 0000035E  48/ 8B 8D					MOV				RCX, savedR9				; divisor
	   FFFFFE58
 00000365  E8 00000000 E				CALL			msb_u						; most significant bit
 0000036A  66| 83 F8 00					CMP				AX, 0						; msb < 0? 
 0000036E  0F 8C 0000027D				JL				divbyzero					; divisor is zero, abort
 00000374  66| 83 F8 40					CMP				AX, 64						; divisor only one 64-bit word?
 00000378  7D 3E					JGE				mbynDiv						; no, do divide of m digit by n digit
							;	divide of m 64-bit digits by one 64 bit divisor
 0000037A  48/ 8B 8D					MOV				RCX, savedRCX				; set up parms for call to div by 64bit: RCX - addr of quotient
	   FFFFFE70
 00000381  48/ 8B 95					MOV				RDX, savedRDX				; RDX - addr of remainder
	   FFFFFE68
 00000388  4C/ 8B 85					MOV				R8, savedR8					; R8 - addr of dividend
	   FFFFFE60
 0000038F  48/ 8B 85					MOV				RAX, savedR9
	   FFFFFE58
 00000396  4C/ 8B 48 38					MOV				R9, Q_PTR [RAX + 7 * 8 ]	; R9 - value of 64 bit divisor
 0000039A  E8 0000025A					CALL			div_uT64
 0000039F  48/ 8B 95					MOV				RDX, savedRDX				; move 64 bit remainder to last word of 8 word remainder
	   FFFFFE68
 000003A6  48/ 8B 02					MOV				RAX, Q_PTR [ RDX ]
 000003A9  48/ 89 42 38					MOV				Q_PTR [ RDX + 7 * 8 ], RAX
 000003AD  48/ 33 C0					XOR				RAX, RAX					; clear first word of remainder (where 64 bit divide put it)
 000003B0  48/ 89 02					MOV				Q_PTR [ RDX ], RAX
 000003B3  E9 000001FC					JMP				cleanupret

				;
				;			Going to divide an 'm' digit dividend (u), by an 'n' digit divisor (v)
				;				See Knuth, The Art of Computer Programming, Volume 2, Algorithm D, Pages 272-278
 000003B8			mbynDiv:
 000003B8  66| 89 85					MOV				dimN, AX					; still have divisor msb in AX
	   FFFFFE16
 000003BF  66| C1 A5					SHL				dimN, 6						; div msb by 6 to get msq (most significant qword) aka 'n'
	   FFFFFE16 06
 000003C7  66| C7 85					MOV				normf, 64
	   FFFFFE1E 0040
 000003D0  66| 29 85					SUB				normf, AX					; Nr bits to get leading divisor bit to msb saved at normf			
	   FFFFFE1E
 000003D7  48/ 33 C0					XOR				RAX, RAX
 000003DA  66| 89 85					MOV				dimM, AX
	   FFFFFE18
 000003E1			@@:
 000003E1  66| FF 85					INC				dimM
	   FFFFFE18
 000003E8  66| 83 BD					CMP				dimM, 8
	   FFFFFE18 08
 000003F0  0F 84 000001BE				JE				cleanupret					; dividend is zero, both quotient and remainder already set to zero, so returm
 000003F6  49/ 3B 00					CMP				RAX, [ R8 ]
 000003F9  4D/ 8D 40 08					LEA				R8, 8 [ R8 ]
 000003FD  74 E2					JZ				@B
 000003FF  66| FF 8D					DEC				dimM						; now have dimensions of divisor (v) which is dimN, and dividend (u) which is dimM
	   FFFFFE18

				;			Step D1: Normalize	
								
 00000406  48/ 8B 95					MOV				RDX, savedR9				; callers divisor
	   FFFFFE58
 0000040D  48/ 8D 8D					LEA				RCX, normdivisor			; local copy of divisor, normalized
	   FFFFFE80
 00000414  66| 44/ 8B 85				MOV				R8W, normf
	   FFFFFE1E
 0000041C  E8 00000000 E				CALL			shl_u						; by shifting until MSB is high bit
							;
 00000421  48/ 8B 95					MOV				RDX, savedR8				; callers dividend
	   FFFFFE60
 00000428  48/ 8D 4D 80					LEA				RCX, currnumerator [ 8 * 8 ]; starting numerator is the normalized supplied dividend
 0000042C  66| 44/ 8B 85				MOV				R8W, normf
	   FFFFFE1E
 00000434  E8 00000000 E				CALL			shl_u
 00000439  48/ 8B 95					MOV				RDX, savedR8
	   FFFFFE60
 00000440  48/ 8D 8D					LEA				RCX, currnumerator [ 0 * 8 ]
	   FFFFFF40
 00000447  66| 41/ B8					MOV				R8W, 64
	   0040
 0000044C  66| 44/ 2B 85				SUB				R8W, normf
	   FFFFFE1E
 00000454  E8 00000000 E				CALL			shr_u						; now have up to 16 word bit-shifted dividend in 'enumerator'
 00000459  48/ 8D 8D					LEA				RCX, currnumerator
	   FFFFFF40
 00000460			@@:
 00000460  48/ 89 8D					MOV				currenumbegin, RCX			; set address of the first non-zero word of the dividend (enumerator)
	   FFFFFE20
 00000467  48/ 8B 11					MOV				RDX, [ RCX ]
 0000046A  48/ 85 D2					TEST			RDX, RDX
 0000046D  48/ 8D 49 08					LEA				RCX, [ RCX + 8 ]
 00000471  74 ED					JZ				@B
 00000473  48/ 0F B7 8D					MOVZX			RCX, normf
	   FFFFFE1E
 0000047B  66| C1 E9 04					SHR				CX, 4
 0000047F  66| 89 8D					MOV				limEnumIdx, CX
	   FFFFFE1C
				;			Step D2: Initialize
 00000486  48/ 33 C0					XOR				RAX, RAX
 00000489  66| 89 85					MOV				jIdx, AX
	   FFFFFE1A

				;			Step D3: Calculate  q^
 00000490			D3:
 00000490  48/ 33 D2					XOR				RDX, RDX					; DIV takes 128 bits, RDX the high 64, RAX the low
 00000493  48/ 0F B7 85					MOVZX			RAX, jIdx
	   FFFFFE1A
 0000049B  48/ 8B 8D					MOV				RCX, currenumbegin
	   FFFFFE20
 000004A2  48/ 8D 0C C1					LEA				RCX, [ RCX + RAX * 8 ]
 000004A6  48/ 8B 11					MOV				RDX, [ RCX ]
 000004A9  48/ 8B 41 08					MOV				RAX, [ RCX + 8 ]
 000004AD  48/ 8B 8D					MOV				RCX, normdivisor
	   FFFFFE80
 000004B4  48/ F7 F1					DIV				RCX
 000004B7  48/ 89 85					MOV				qHat, RAX
	   FFFFFE38
 000004BE  48/ 89 95					MOV				rHat, RDX
	   FFFFFE30
				;			test q^
 000004C5			@retest:
 000004C5  48/ 85 C0					TEST			RAX, RAX					; q^ = b? (2^64)
 000004C8  74 34					JZ				@adj
 000004CA  48/ F7 A5					MUL				normdivisor [ 1 * 8 ]
	   FFFFFE88
 000004D1  48/ 0F B7 8D					MOVZX			RCX, jIdx
	   FFFFFE1A
 000004D9  4C/ 8B 85					MOV				R8, currenumbegin
	   FFFFFE20
 000004E0  49/ 8B 4C C8					MOV				RCX, [ R8 + RCX * 8 + 16]
	   10
 000004E5  48/ 03 8D					ADD				RCX, rHat
	   FFFFFE30
 000004EC  72 05					JC				@5
 000004EE  48/ 3B C1					CMP				RAX, RCX
 000004F1  7F 0B					JG				@adj
 000004F3  48/ 83 FA 01		@5:			CMP				RDX, 1
 000004F7  7F 05					JG				@adj
 000004F9  48/ 3B C1					CMP				RAX, RCX
 000004FC  7E 2B					JLE				D4
 000004FE			@adj:
 000004FE  48/ 8B 85					MOV				RAX, qHat
	   FFFFFE38
 00000505  48/ FF C8					DEC				RAX
 00000508  48/ 89 85					MOV				qHat, RAX
	   FFFFFE38
 0000050F  48/ 8B C1					MOV				RAX, RCX
 00000512  48/ 03 85					ADD				RAX, rHat
	   FFFFFE30
 00000519  48/ 89 85					MOV				rHat, RAX
	   FFFFFE30
 00000520  48/ 8B 85					MOV				RAX, qHat
	   FFFFFE38
 00000527  73 9C					JNC				@retest

				;			Step D4: Multiply and Subtract
 00000529			D4:
 00000529  48/ 8D 8D					LEA				RCX, qdiv
	   FFFFFF00
 00000530  48/ 8D 95					LEA				RDX, qovf
	   FFFFFE28
 00000537  4C/ 8D 85					LEA				R8, normdivisor
	   FFFFFE80
 0000053E  4C/ 8B 8D					MOV				R9, qHat
	   FFFFFE38
 00000545  E8 FFFFFC9D					CALL			mult_uT64					; multiply divisor by trial quotient digit (qHat)
 0000054A  48/ 8B 85					MOV				RAX, qovf
	   FFFFFE28
 00000551  48/ 85 C0					TEST			RAX, RAX
 00000554  75 5E					JNZ				cleanupret
 00000556  48/ 8D 8D					LEA				RCX, currnumerator
	   FFFFFF40
 0000055D  48/ 8D 95					LEA				RDX, currnumerator
	   FFFFFF40
 00000564  4C/ 8D 85					LEA				R8, qdiv
	   FFFFFF00
 0000056B  E8 00000000 E				CALL			sub_u
 00000570  4D/ 8D 64 24					LEA				R12, 8 [ R12 ]
	   08
 00000575  49/ 83 FC 40					CMP				R12, 8 * 8
 00000579  0F 8C FFFFFF11				JL				D3

 0000057F			D8UnNormalize:
 0000057F  48/ 8B 8D					MOV				RCX, savedRDX				; reduced working numerator is now the remainder
	   FFFFFE68
 00000586  48/ 8D 95					LEA				RDX, currnumerator			; copy to callers remainder
	   FFFFFF40
 0000058D  66| 44/ 8B 85				MOV				R8W, normf
	   FFFFFE1E
 00000595  E8 00000000 E				CALL			shr_u
							;
 0000059A  48/ 8B 8D					MOV				RCX, savedRCX				; copy working quotient to callers quotient
	   FFFFFE70
 000005A1  48/ 8D 95					LEA				RDX, quotient
	   FFFFFEC0
							Copy512			RCX, RDX
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0015									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0015:
			     2		ENDIF
			     1					CheckAlign		RDX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RDX, 63							; Is specified param aligned 64?
			     2					JZ				??0016									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0016:
			     2		ENDIF
			     1		IF	__UseZ
 000005A8  62 61 FD 48/ 6F   1					VMOVDQA64		ZMM31, ZM_PTR [ RDX ]
	   3A
 000005AE  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VMOVDQA64		YMM4, YM_PTR [ RDX + 0 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4	; alternate ymm regs in case pipeline can execute next without waiting for this.
			     1					VMOVDQA64		YMM5, YM_PTR [ RDX + 4 * 8 ]
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM5
			     1		ELSEIF	__UseX
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 0 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 2 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM3
			     1					MOVDQA			XMM4, XM_PTR [ RDX + 4 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XMM3, XM_PTR [ RDX + 6 * 8 ]
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM3
			     1		ELSE
			     1					MOV				RAX, [ RDX + 0 * 8 ]
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 1 * 8 ]
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 2 * 8 ]
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 3 * 8 ]
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 4 * 8 ]
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 5 * 8 ]
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 6 * 8 ]
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				RAX, [ RDX + 7 * 8 ]
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 000005B4			cleanupret:
 000005B4  4C/ 8B A5					MOV				R12, savedR12
	   FFFFFE40
 000005BB  4C/ 8B 9D					MOV				R11, savedR11
	   FFFFFE48
 000005C2  4C/ 8B 95					MOV				R10, savedR10
	   FFFFFE50
 000005C9  4C/ 8B 8D					MOV				R9,  savedR9
	   FFFFFE58
 000005D0  4C/ 8B 85					MOV				R8,  savedR8
	   FFFFFE60
 000005D7  48/ 8B 95					MOV				RDX, savedRDX
	   FFFFFE68
 000005DE  48/ 8B 8D					MOV				RCX, savedRCX				; restore parameter registers back to "as-called" values
	   FFFFFE70
							ReleaseFrame	savedRBP
			     1	;			release memory set up by createframe macro
			     1	;			restores RSP, and RBP to as-called values
			     1	;			after these instructions are executed, no LOCAL variables can be accessed
			     1	;			This needs to be done to restore the stack correctly, but can be done only once
			     1	;			Strongly suggest doing this just prior to return instruction, and that there is only one return instruction from the PROC
 000005E5  48/ 8B AD	     1				MOV				RBP, savedRBP
	   FFFFFE78
 000005EC  C9		     1				LEAVE										; restore stack pointer (eliminating LOCAL storage), restore base pointer for caller
 000005ED  48/ 33 C0					XOR				RAX, RAX					; return zero
 000005F0			exit:
							RET
 000005F0  C3		   *	    ret    00000h
 000005F1			divbyzero:
 000005F1  8B 05 00000008 R				MOV				EAX, ret_1
 000005F7  EB F7					JMP				exit

 000005F9			div_u		ENDP

				;
				;--------------------------------------------------------------------------------------------------------------------------------------------------------------
				;			EXTERNDEF		div_uT64:PROC				; s16 div_uT64( u64* quotient, u64* remainder, u64* dividend, u64 divisor)
				;			div_uT64		-	divide 512 bit dividend by 64 bit divisor, giving 512 bit quotient and 64 bit remainder
				;			Prototype:		-	s16 div_u( u64* quotient, u64* remainder, u64* dividend, u64 divisor);
				;			quotient		-	Address of 8 QWORDS to store resulting quotient (in RCX)
				;			remainder		-	Address of QWORD for resulting remainder (in RDX)
				;			dividend		-	Address of 8 QWORDS dividend (in R8)
				;			divisor			-	Value of 64 bit divisor (in R9)
				;			returns			-	0 for success, -1 for attempt to divide by zero

							OPTION			PROLOGUE:none
							OPTION			EPILOGUE:none
 000005F9			div_uT64	PROC			PUBLIC

 000005F9  4D/ 85 C9					TEST			R9, R9
 000005FC  74 63					JZ				@@DivByZero
							;
 000005FE  4C/ 8B D2					MOV				R10, RDX
 00000601  48/ 33 D2					XOR				RDX, RDX
 00000604  49/ 8B 00					MOV				RAX, Q_PTR [ R8 + 0 * 8 ]		; Dividend first word
 00000607  49/ F7 F1					DIV				R9								; Divisor
 0000060A  48/ 89 01					MOV				Q_PTR [ RCX + 0 * 8 ], RAX		; Quotient to callers quotient first word; Div moved remainder to RDX
 0000060D  49/ 8B 40 08					MOV				RAX, Q_PTR [ R8 + 1 * 8 ]		; 2nd
 00000611  49/ F7 F1					DIV				R9
 00000614  48/ 89 41 08					MOV				Q_PTR [ RCX + 1 * 8 ], RAX
 00000618  49/ 8B 40 10					MOV				RAX, Q_PTR [ R8 + 2 * 8 ]		; 3rd
 0000061C  49/ F7 F1					DIV				R9
 0000061F  48/ 89 41 10					MOV				Q_PTR [ RCX + 2 * 8 ], RAX
 00000623  49/ 8B 40 18					MOV				RAX, Q_PTR [ R8 + 3 * 8 ]		; 4th
 00000627  49/ F7 F1					DIV				R9
 0000062A  48/ 89 41 18					MOV				Q_PTR [ RCX + 3 * 8 ], RAX
 0000062E  49/ 8B 40 20					MOV				RAX, Q_PTR [ R8 + 4 * 8 ]		; 5th
 00000632  49/ F7 F1					DIV				R9
 00000635  48/ 89 41 20					MOV				Q_PTR [ RCX + 4 * 8 ], RAX
 00000639  49/ 8B 40 28					MOV				RAX, Q_PTR [ R8 + 5 * 8 ]		; 6th
 0000063D  49/ F7 F1					DIV				R9
 00000640  48/ 89 41 28					MOV				Q_PTR [ RCX + 5 * 8 ], RAX
 00000644  49/ 8B 40 30					MOV				RAX, Q_PTR [ R8 + 6 * 8 ]		; 7th
 00000648  49/ F7 F1					DIV				R9
 0000064B  48/ 89 41 30					MOV				Q_PTR [ RCX + 6 * 8 ], RAX		; 8th and final
 0000064F  49/ 8B 40 38					MOV				RAX, Q_PTR [ R8 + 7 * 8 ]
 00000653  49/ F7 F1					DIV				R9
 00000656  48/ 89 41 38					MOV				Q_PTR [ RCX + 7 * 8 ], RAX
 0000065A  49/ 89 12					MOV				Q_PTR [ R10 ], RDX				; remainder to callers remainder
 0000065D  48/ 33 C0					XOR				RAX, RAX						; return zero
 00000660			@@exit:			
 00000660  C3						RET

				;
 00000661			@@DivByZero:
							Zero512			RCX								; Divide by Zero. Could throw fault, but returning zero quotient, zero remainder
			     1					CheckAlign		RCX
			     2					LOCAL			ok
			     2		IF	__CheckAlign
			     2					TEST			RCX, 63							; Is specified param aligned 64?
			     2					JZ				??0017									; Yes, passes test, continue
			     2					INT				0									; No, fails, break (can substitute other exception handling)
			     2	??0017:
			     2		ENDIF
			     1		IF	__UseZ
 00000661  62 01 85 40/ EF   1					VPXORQ			ZMM31, ZMM31, ZMM31
	   FF
 00000667  62 61 FD 48/ 7F   1					VMOVDQA64		ZM_PTR [ RCX ], ZMM31
	   39
			     1		ELSEIF	__UseY
			     1					VPXORQ			YMM4, YMM4, YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 0 * 8 ], YMM4
			     1					VMOVDQA64		YM_PTR [ RCX + 4 * 8 ], YMM4
			     1		ELSEIF	__UseX
			     1					PXOR			XMM4, XMM4
			     1					MOVDQA			XM_PTR [ RCX + 0 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 2 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 4 * 8 ], XMM4
			     1					MOVDQA			XM_PTR [ RCX + 6 * 8 ], XMM4			
			     1		ELSE
			     1					XOR				RAX, RAX
			     1					MOV				[ RCX + 0 * 8 ], RAX
			     1					MOV				[ RCX + 1 * 8 ], RAX
			     1					MOV				[ RCX + 2 * 8 ], RAX
			     1					MOV				[ RCX + 3 * 8 ], RAX
			     1					MOV				[ RCX + 4 * 8 ], RAX
			     1					MOV				[ RCX + 5 * 8 ], RAX
			     1					MOV				[ RCX + 6 * 8 ], RAX
			     1					MOV				[ RCX + 7 * 8 ], RAX
			     1		ENDIF
 0000066D  48/ 33 C0					XOR				RAX, RAX
 00000670  49/ 89 02					MOV				Q_PTR [ R10 ] , RAX				;
 00000673  8B 05 00000008 R				MOV				EAX, ret_1							; return error (div by zero)
 00000679  EB E5					JMP				@@exit
 0000067B			div_uT64	ENDP

							END
Microsoft (R) Macro Assembler (x64) Version 14.43.34808.0   03/02/25 21:27:13
ui512md.asm						     Symbols 2 - 1




Macros:

                N a m e                 Type

CheckAlign . . . . . . . . . . .	Proc
Copy512  . . . . . . . . . . . .	Proc
CreateFrame  . . . . . . . . . .	Proc
GetZatMask . . . . . . . . . . .	Proc
MemConstants . . . . . . . . . .	Proc
ReleaseFrame . . . . . . . . . .	Proc
SetZatMask . . . . . . . . . . .	Proc
Zero512  . . . . . . . . . . . .	Proc


Segments:

                N a m e                  Length   Align   Class

ui512md  . . . . . . . . . . . .	 0000067B 16	  'CODE'	


Procedures, parameters, and locals:

                N a m e                 Type     Value    Attr

div_uT64 . . . . . . . . . . . .	P 	 000005F9 ui512md	Length= 00000082 Public
  @@exit . . . . . . . . . . . .	L 	 00000660 ui512md	
  @@DivByZero  . . . . . . . . .	L 	 00000661 ui512md	
div_u  . . . . . . . . . . . . .	P 	 000002DE ui512md	Length= 0000031B Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  currnumerator  . . . . . . . .	QWord	 rbp - 000000C0
  qdiv . . . . . . . . . . . . .	QWord	 rbp - 00000100
  quotient . . . . . . . . . . .	QWord	 rbp - 00000140
  normdivisor  . . . . . . . . .	QWord	 rbp - 00000180
  savedRBP . . . . . . . . . . .	QWord	 rbp - 00000188
  savedRCX . . . . . . . . . . .	QWord	 rbp - 00000190
  savedRDX . . . . . . . . . . .	QWord	 rbp - 00000198
  savedR8  . . . . . . . . . . .	QWord	 rbp - 000001A0
  savedR9  . . . . . . . . . . .	QWord	 rbp - 000001A8
  savedR10 . . . . . . . . . . .	QWord	 rbp - 000001B0
  savedR11 . . . . . . . . . . .	QWord	 rbp - 000001B8
  savedR12 . . . . . . . . . . .	QWord	 rbp - 000001C0
  qHat . . . . . . . . . . . . .	QWord	 rbp - 000001C8
  rHat . . . . . . . . . . . . .	QWord	 rbp - 000001D0
  qovf . . . . . . . . . . . . .	QWord	 rbp - 000001D8
  currenumbegin  . . . . . . . .	QWord	 rbp - 000001E0
  normf  . . . . . . . . . . . .	Word	 rbp - 000001E2
  limEnumIdx . . . . . . . . . .	Word	 rbp - 000001E4
  jIdx . . . . . . . . . . . . .	Word	 rbp - 000001E6
  dimM . . . . . . . . . . . . .	Word	 rbp - 000001E8
  dimN . . . . . . . . . . . . .	Word	 rbp - 000001EA
  padding2 . . . . . . . . . . .	QWord	 rbp - 0000026C
  mbynDiv  . . . . . . . . . . .	L 	 000003B8 ui512md	
  D3 . . . . . . . . . . . . . .	L 	 00000490 ui512md	
  @retest  . . . . . . . . . . .	L 	 000004C5 ui512md	
  @5 . . . . . . . . . . . . . .	L 	 000004F3 ui512md	
  @adj . . . . . . . . . . . . .	L 	 000004FE ui512md	
  D4 . . . . . . . . . . . . . .	L 	 00000529 ui512md	
  D8UnNormalize  . . . . . . . .	L 	 0000057F ui512md	
  cleanupret . . . . . . . . . .	L 	 000005B4 ui512md	
  exit . . . . . . . . . . . . .	L 	 000005F0 ui512md	
  divbyzero  . . . . . . . . . .	L 	 000005F1 ui512md	
mult_uT64  . . . . . . . . . . .	P 	 000001E7 ui512md	Length= 000000F7 Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  product  . . . . . . . . . . .	QWord	 rbp - 00000080
  savedRBP . . . . . . . . . . .	QWord	 rbp - 00000088
  savedRCX . . . . . . . . . . .	QWord	 rbp - 00000090
  savedRDX . . . . . . . . . . .	QWord	 rbp - 00000098
  overflow . . . . . . . . . . .	QWord	 rbp - 000000A0
  padding2 . . . . . . . . . . .	QWord	 rbp - 000000E0
mult_u . . . . . . . . . . . . .	P 	 00000019 ui512md	Length= 000001CE Public
  padding1 . . . . . . . . . . .	QWord	 rbp - 00000040
  product  . . . . . . . . . . .	QWord	 rbp - 000000C0
  savedRBP . . . . . . . . . . .	QWord	 rbp - 000000C8
  savedRCX . . . . . . . . . . .	QWord	 rbp - 000000D0
  savedRDX . . . . . . . . . . .	QWord	 rbp - 000000D8
  savedR10 . . . . . . . . . . .	QWord	 rbp - 000000E0
  savedR11 . . . . . . . . . . .	QWord	 rbp - 000000E8
  savedR12 . . . . . . . . . . .	QWord	 rbp - 000000F0
  plierl . . . . . . . . . . . .	Word	 rbp - 000000F2
  candl  . . . . . . . . . . . .	Word	 rbp - 000000F4
  padding2 . . . . . . . . . . .	QWord	 rbp - 00000174
  @@multloop . . . . . . . . . .	L 	 000000F2 ui512md	
  @@exit . . . . . . . . . . . .	L 	 00000176 ui512md	
  @@zeroandexit  . . . . . . . .	L 	 00000197 ui512md	
  @@copyandexit  . . . . . . . .	L 	 000001BF ui512md	


Symbols:

                N a m e                 Type     Value    Attr

B_PTR  . . . . . . . . . . . . .	Text   	 BYTE PTR
CPEQ . . . . . . . . . . . . . .	Number	 00000000h   
CPFALSE  . . . . . . . . . . . .	Number	 00000003h   
CPGE . . . . . . . . . . . . . .	Number	 00000005h   
CPGT . . . . . . . . . . . . . .	Number	 00000006h   
CPLE . . . . . . . . . . . . . .	Number	 00000002h   
CPLT . . . . . . . . . . . . . .	Number	 00000001h   
CPNE . . . . . . . . . . . . . .	Number	 00000004h   
CPTRUE . . . . . . . . . . . . .	Number	 00000007h   
D_PTR  . . . . . . . . . . . . .	Text   	 DWORD PTR
Mask20 . . . . . . . . . . . . .	Text   	 
MaskBit0 . . . . . . . . . . . .	Number	 00000001h   
MaskBit1 . . . . . . . . . . . .	Number	 00000002h   
MaskBit2 . . . . . . . . . . . .	Number	 00000004h   
MaskBit3 . . . . . . . . . . . .	Number	 00000008h   
MaskBit4 . . . . . . . . . . . .	Number	 00000010h   
MaskBit5 . . . . . . . . . . . .	Number	 00000020h   
MaskBit6 . . . . . . . . . . . .	Number	 00000040h   
MaskBit7 . . . . . . . . . . . .	Number	 00000080h   
Q_PTR  . . . . . . . . . . . . .	Text   	 QWORD PTR
W_PTR  . . . . . . . . . . . . .	Text   	 WORD PTR
XM_PTR . . . . . . . . . . . . .	Text   	 XMMWORD PTR
YM_PTR . . . . . . . . . . . . .	Text   	 YMMWORD PTR
ZM_PTR . . . . . . . . . . . . .	Text   	 ZMMWORD PTR
__CheckAlign . . . . . . . . . .	Number	 00000000h   
__UseQ . . . . . . . . . . . . .	Number	 00000000h   
__UseX . . . . . . . . . . . . .	Number	 00000000h   
__UseY . . . . . . . . . . . . .	Number	 00000000h   
__UseZ . . . . . . . . . . . . .	Number	 00000001h   
add_uT64 . . . . . . . . . . . .	L 	 00000000 External
add_u  . . . . . . . . . . . . .	L 	 00000000 External
and_u  . . . . . . . . . . . . .	L 	 00000000 External
compare_uT64 . . . . . . . . . .	L 	 00000000 External
compare_u  . . . . . . . . . . .	L 	 00000000 External
copy_u . . . . . . . . . . . . .	L 	 00000000 External
div_oset . . . . . . . . . . . .	Text   	 padding2 + 64 - padding1
lsb_u  . . . . . . . . . . . . .	L 	 00000000 External
m32BCST  . . . . . . . . . . . .	Text   	 DWORD BCST
m64BCST  . . . . . . . . . . . .	Text   	 QWORD BCST
msb_u  . . . . . . . . . . . . .	L 	 00000000 External
mskAll8  . . . . . . . . . . . .	Byte	 0000000C ui512md	
mskB0  . . . . . . . . . . . . .	Byte	 0000000D ui512md	
mskB1  . . . . . . . . . . . . .	Byte	 0000000E ui512md	
mskB2  . . . . . . . . . . . . .	Byte	 0000000F ui512md	
mskB3  . . . . . . . . . . . . .	Byte	 00000010 ui512md	
mskB4  . . . . . . . . . . . . .	Byte	 00000011 ui512md	
mskB5  . . . . . . . . . . . . .	Byte	 00000012 ui512md	
mskB6  . . . . . . . . . . . . .	Byte	 00000013 ui512md	
mskB7  . . . . . . . . . . . . .	Byte	 00000014 ui512md	
mskHex100  . . . . . . . . . . .	DWord	 00000015 ui512md	
mult64_oset  . . . . . . . . . .	Text   	 padding2 + 64 - padding1
mult_u_ofs . . . . . . . . . . .	Text   	 padding2 + 64 - padding1
not_u  . . . . . . . . . . . . .	L 	 00000000 External
or_u . . . . . . . . . . . . . .	L 	 00000000 External
ret0 . . . . . . . . . . . . . .	DWord	 00000000 ui512md	
ret1 . . . . . . . . . . . . . .	DWord	 00000004 ui512md	
ret_1  . . . . . . . . . . . . .	DWord	 00000008 ui512md	
set_uT64 . . . . . . . . . . . .	L 	 00000000 External
shl_u  . . . . . . . . . . . . .	L 	 00000000 External
shr_u  . . . . . . . . . . . . .	L 	 00000000 External
sub_uT64 . . . . . . . . . . . .	L 	 00000000 External
sub_u  . . . . . . . . . . . . .	L 	 00000000 External
ui512aMacros_INC . . . . . . . .	Text   	 1
ui512bMacros_INC . . . . . . . .	Text   	 1
ui512mdMacros_INC  . . . . . . .	Text   	 1
zero_u . . . . . . . . . . . . .	L 	 00000000 External

	   0 Warnings
	   0 Errors
